<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 28 Modelo de regresión lineal múltiple | Modelos no paramétricos y de Regresión</title>
  <meta name="description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 28 Modelo de regresión lineal múltiple | Modelos no paramétricos y de Regresión" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/Dul-Reyes/MNPyR" />
  
  <meta property="og:description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  <meta name="github-repo" content="Dul-Reyes/MNPyR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 28 Modelo de regresión lineal múltiple | Modelos no paramétricos y de Regresión" />
  
  <meta name="twitter:description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  

<meta name="author" content="Sofía Villers Gómez" />
<meta name="author" content="Dulce María Reyes Varela" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="validación-de-supuestos.html"/>
<link rel="next" href="intervalos-de-confianza-2.html"/>
<script src="libs/header-attrs-2.7.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos no paramétricos y de Regresión</a></li>

<li class="divider"></li>
<li><a href="index.html#prefacio" id="toc-prefacio">Prefacio</a>
<ul>
<li><a href="index.html#objetivos" id="toc-objetivos">Objetivos</a></li>
<li><a href="index.html#licencia" id="toc-licencia">Licencia</a></li>
</ul></li>
<li><a href="introducción.html#introducción" id="toc-introducción">Introducción</a></li>
<li><a href="#part-un-primer-vistazo" id="toc-part-un-primer-vistazo">(PART) Un primer vistazo</a></li>
<li><a href="escalas-de-medición.html#escalas-de-medición" id="toc-escalas-de-medición"><span class="toc-section-number">1</span> Escalas de Medición</a>
<ul>
<li><a href="escalas-de-medición.html#variables-categóricas" id="toc-variables-categóricas"><span class="toc-section-number">1.1</span> Variables categóricas</a>
<ul>
<li><a href="escalas-de-medición.html#escala-nominal" id="toc-escala-nominal"><span class="toc-section-number">1.1.1</span> Escala nominal:</a></li>
<li><a href="escalas-de-medición.html#escala-ordinal" id="toc-escala-ordinal"><span class="toc-section-number">1.1.2</span> Escala ordinal:</a></li>
</ul></li>
<li><a href="escalas-de-medición.html#variables-cuantitativas" id="toc-variables-cuantitativas"><span class="toc-section-number">1.2</span> Variables cuantitativas</a>
<ul>
<li><a href="escalas-de-medición.html#escala-de-intervalo" id="toc-escala-de-intervalo"><span class="toc-section-number">1.2.1</span> Escala de intervalo:</a></li>
<li><a href="escalas-de-medición.html#escala-de-razón" id="toc-escala-de-razón"><span class="toc-section-number">1.2.2</span> Escala de razón:</a></li>
</ul></li>
</ul></li>
<li><a href="#part-pruebas-binomiales" id="toc-part-pruebas-binomiales">(PART) Pruebas Binomiales</a></li>
<li><a href="introducción-1.html#introducción-1" id="toc-introducción-1">Introducción</a></li>
<li><a href="prueba-de-proporciones.html#prueba-de-proporciones" id="toc-prueba-de-proporciones"><span class="toc-section-number">2</span> Prueba de Proporciones</a>
<ul>
<li><a href="prueba-de-proporciones.html#datos" id="toc-datos"><span class="toc-section-number">2.1</span> Datos</a></li>
<li><a href="prueba-de-proporciones.html#supuestos" id="toc-supuestos"><span class="toc-section-number">2.2</span> Supuestos</a></li>
<li><a href="prueba-de-proporciones.html#estadístico-de-prueba" id="toc-estadístico-de-prueba"><span class="toc-section-number">2.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-proporciones.html#hipótesis" id="toc-hipótesis"><span class="toc-section-number">2.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-proporciones.html#caso-a-prueba-de-dos-colas" id="toc-caso-a-prueba-de-dos-colas">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-proporciones.html#caso-b-prueba-de-cola-inferior" id="toc-caso-b-prueba-de-cola-inferior">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-proporciones.html#caso-c-prueba-de-cola-superior" id="toc-caso-c-prueba-de-cola-superior">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-proporciones.html#intervalos-de-confianza" id="toc-intervalos-de-confianza"><span class="toc-section-number">2.5</span> Intervalos de Confianza</a></li>
<li><a href="prueba-de-proporciones.html#ejemplo" id="toc-ejemplo"><span class="toc-section-number">2.6</span> Ejemplo</a></li>
<li><a href="prueba-de-proporciones.html#ejemplo-en-r-studio" id="toc-ejemplo-en-r-studio"><span class="toc-section-number">2.7</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-proporciones.html#ejercicios" id="toc-ejercicios"><span class="toc-section-number">2.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-cuantiles.html#prueba-de-cuantiles" id="toc-prueba-de-cuantiles"><span class="toc-section-number">3</span> Prueba de Cuantiles</a>
<ul>
<li><a href="prueba-de-cuantiles.html#datos-1" id="toc-datos-1"><span class="toc-section-number">3.1</span> Datos</a></li>
<li><a href="prueba-de-cuantiles.html#supuestos-1" id="toc-supuestos-1"><span class="toc-section-number">3.2</span> Supuestos</a></li>
<li><a href="prueba-de-cuantiles.html#estadístico-de-prueba-1" id="toc-estadístico-de-prueba-1"><span class="toc-section-number">3.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-cuantiles.html#hipótesis-1" id="toc-hipótesis-1"><span class="toc-section-number">3.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-cuantiles.html#caso-a-prueba-de-dos-colas-1" id="toc-caso-a-prueba-de-dos-colas-1">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-cuantiles.html#caso-b-prueba-de-cola-inferior-1" id="toc-caso-b-prueba-de-cola-inferior-1">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-cuantiles.html#caso-c-prueba-de-cola-supeior" id="toc-caso-c-prueba-de-cola-supeior">Caso C (Prueba de cola supeior)</a></li>
</ul></li>
<li><a href="prueba-de-cuantiles.html#ejemplo-1" id="toc-ejemplo-1"><span class="toc-section-number">3.5</span> Ejemplo</a></li>
<li><a href="prueba-de-cuantiles.html#ejemplo-en-r-studio-1" id="toc-ejemplo-en-r-studio-1"><span class="toc-section-number">3.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-cuantiles.html#ejercicios-1" id="toc-ejercicios-1"><span class="toc-section-number">3.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-signos.html#prueba-de-signos" id="toc-prueba-de-signos"><span class="toc-section-number">4</span> Prueba de Signos</a>
<ul>
<li><a href="prueba-de-signos.html#datos-2" id="toc-datos-2"><span class="toc-section-number">4.1</span> Datos</a></li>
<li><a href="prueba-de-signos.html#supuestos-2" id="toc-supuestos-2"><span class="toc-section-number">4.2</span> Supuestos</a></li>
<li><a href="prueba-de-signos.html#estadístico-de-prueba-2" id="toc-estadístico-de-prueba-2"><span class="toc-section-number">4.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-signos.html#hipótesis-2" id="toc-hipótesis-2"><span class="toc-section-number">4.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-signos.html#caso-a-prueba-de-dos-colas-2" id="toc-caso-a-prueba-de-dos-colas-2">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-signos.html#caso-b-prueba-de-cola-inferior-2" id="toc-caso-b-prueba-de-cola-inferior-2">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-signos.html#caso-c-prueba-de-cola-superior-1" id="toc-caso-c-prueba-de-cola-superior-1">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-signos.html#ejemplo-2" id="toc-ejemplo-2"><span class="toc-section-number">4.5</span> Ejemplo</a></li>
<li><a href="prueba-de-signos.html#ejemplo-en-r-studio-2" id="toc-ejemplo-en-r-studio-2"><span class="toc-section-number">4.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-signos.html#ejercicios-2" id="toc-ejercicios-2"><span class="toc-section-number">4.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-mc-nemar.html#prueba-mc-nemar" id="toc-prueba-mc-nemar"><span class="toc-section-number">5</span> Prueba Mc Nemar</a>
<ul>
<li><a href="prueba-mc-nemar.html#datos-3" id="toc-datos-3"><span class="toc-section-number">5.1</span> Datos</a></li>
<li><a href="prueba-mc-nemar.html#supuestos-3" id="toc-supuestos-3"><span class="toc-section-number">5.2</span> Supuestos</a></li>
<li><a href="prueba-mc-nemar.html#estadístico-de-prueba-3" id="toc-estadístico-de-prueba-3"><span class="toc-section-number">5.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-mc-nemar.html#hipótesis-3" id="toc-hipótesis-3"><span class="toc-section-number">5.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-mc-nemar.html#caso-a-prueba-de-dos-colas-3" id="toc-caso-a-prueba-de-dos-colas-3">Caso A (Prueba de dos colas)</a></li>
</ul></li>
<li><a href="prueba-mc-nemar.html#ejemplo-3" id="toc-ejemplo-3"><span class="toc-section-number">5.5</span> Ejemplo</a></li>
<li><a href="prueba-mc-nemar.html#ejemplo-en-r-studio-3" id="toc-ejemplo-en-r-studio-3"><span class="toc-section-number">5.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-mc-nemar.html#ejercicios-3" id="toc-ejercicios-3"><span class="toc-section-number">5.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-cox-stuart.html#prueba-de-cox-stuart" id="toc-prueba-de-cox-stuart"><span class="toc-section-number">6</span> Prueba de Cox Stuart</a>
<ul>
<li><a href="prueba-de-cox-stuart.html#datos-4" id="toc-datos-4"><span class="toc-section-number">6.1</span> Datos</a></li>
<li><a href="prueba-de-cox-stuart.html#supuestos-4" id="toc-supuestos-4"><span class="toc-section-number">6.2</span> Supuestos</a></li>
<li><a href="prueba-de-cox-stuart.html#estadístico-de-prueba-4" id="toc-estadístico-de-prueba-4"><span class="toc-section-number">6.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-cox-stuart.html#hipótesis-4" id="toc-hipótesis-4"><span class="toc-section-number">6.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-cox-stuart.html#caso-a-prueba-de-dos-colas-4" id="toc-caso-a-prueba-de-dos-colas-4">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-cox-stuart.html#caso-b-prueba-de-cola-inferior-3" id="toc-caso-b-prueba-de-cola-inferior-3">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-cox-stuart.html#caso-c-prueba-de-cola-superior-2" id="toc-caso-c-prueba-de-cola-superior-2">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-cox-stuart.html#ejemplo-4" id="toc-ejemplo-4"><span class="toc-section-number">6.5</span> Ejemplo</a></li>
<li><a href="prueba-de-cox-stuart.html#ejemplo-en-r-studio-4" id="toc-ejemplo-en-r-studio-4"><span class="toc-section-number">6.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-cox-stuart.html#ejercicios-4" id="toc-ejercicios-4"><span class="toc-section-number">6.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="#part-prueba-de-rango" id="toc-part-prueba-de-rango">(PART) Prueba de Rango</a></li>
<li><a href="introducción-2.html#introducción-2" id="toc-introducción-2">Introducción</a></li>
<li><a href="prueba-u-mann-y-witney.html#prueba-u-mann-y-witney" id="toc-prueba-u-mann-y-witney"><span class="toc-section-number">7</span> Prueba U-Mann y Witney</a>
<ul>
<li><a href="prueba-u-mann-y-witney.html#datos-5" id="toc-datos-5"><span class="toc-section-number">7.1</span> Datos</a></li>
<li><a href="prueba-u-mann-y-witney.html#supuestos-5" id="toc-supuestos-5"><span class="toc-section-number">7.2</span> Supuestos</a></li>
<li><a href="prueba-u-mann-y-witney.html#estadístico-de-prueba-5" id="toc-estadístico-de-prueba-5"><span class="toc-section-number">7.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-u-mann-y-witney.html#hipótesis-5" id="toc-hipótesis-5"><span class="toc-section-number">7.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-u-mann-y-witney.html#caso-a-prueba-de-dos-colas-5" id="toc-caso-a-prueba-de-dos-colas-5">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-u-mann-y-witney.html#caso-b-prueba-de-cola-inferior-4" id="toc-caso-b-prueba-de-cola-inferior-4">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-u-mann-y-witney.html#caso-c-prueba-de-cola-superior-3" id="toc-caso-c-prueba-de-cola-superior-3">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-u-mann-y-witney.html#ejemplo-5" id="toc-ejemplo-5"><span class="toc-section-number">7.5</span> Ejemplo</a></li>
<li><a href="prueba-u-mann-y-witney.html#ejemplo-en-r-studio-5" id="toc-ejemplo-en-r-studio-5"><span class="toc-section-number">7.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#intervalo-de-confianza-para-la-diferencia-entre-dos-medias" id="toc-intervalo-de-confianza-para-la-diferencia-entre-dos-medias"><span class="toc-section-number">8</span> Intervalo de confianza para la diferencia entre dos medias</a>
<ul>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#datos-6" id="toc-datos-6"><span class="toc-section-number">8.1</span> Datos</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#supuestos-6" id="toc-supuestos-6"><span class="toc-section-number">8.2</span> Supuestos</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#método" id="toc-método"><span class="toc-section-number">8.3</span> Método</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#ejemplo-6" id="toc-ejemplo-6"><span class="toc-section-number">8.4</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-de-kruskal-wallis.html#prueba-de-kruskal-wallis" id="toc-prueba-de-kruskal-wallis"><span class="toc-section-number">9</span> Prueba de Kruskal-Wallis</a>
<ul>
<li><a href="prueba-de-kruskal-wallis.html#datos-7" id="toc-datos-7"><span class="toc-section-number">9.1</span> Datos</a></li>
<li><a href="prueba-de-kruskal-wallis.html#supuestos-7" id="toc-supuestos-7"><span class="toc-section-number">9.2</span> Supuestos</a></li>
<li><a href="prueba-de-kruskal-wallis.html#hipótesis-6" id="toc-hipótesis-6"><span class="toc-section-number">9.3</span> Hipótesis</a></li>
<li><a href="prueba-de-kruskal-wallis.html#estadístico-de-prueba-6" id="toc-estadístico-de-prueba-6"><span class="toc-section-number">9.4</span> Estadístico de prueba</a></li>
<li><a href="prueba-de-kruskal-wallis.html#regla-de-decisión-16" id="toc-regla-de-decisión-16"><span class="toc-section-number">9.5</span> Regla de decisión</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejemplo-7" id="toc-ejemplo-7"><span class="toc-section-number">9.6</span> Ejemplo</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejemplo-en-r-studio-6" id="toc-ejemplo-en-r-studio-6"><span class="toc-section-number">9.7</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejercicios-5" id="toc-ejercicios-5"><span class="toc-section-number">9.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#prueba-de-igualdad-de-varianzas" id="toc-prueba-de-igualdad-de-varianzas"><span class="toc-section-number">10</span> Prueba de Igualdad de Varianzas</a>
<ul>
<li><a href="prueba-de-igualdad-de-varianzas.html#prueba-de-igualdad-de-varianzas-para-2-poblaciones" id="toc-prueba-de-igualdad-de-varianzas-para-2-poblaciones">Prueba de Igualdad de Varianzas para 2 poblaciones</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#datos-8" id="toc-datos-8"><span class="toc-section-number">10.1</span> Datos</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#supuestos-8" id="toc-supuestos-8"><span class="toc-section-number">10.2</span> Supuestos</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#estadístico-de-prueba-7" id="toc-estadístico-de-prueba-7"><span class="toc-section-number">10.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#hipótesis-7" id="toc-hipótesis-7"><span class="toc-section-number">10.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-a-prueba-de-dos-colas-6" id="toc-caso-a-prueba-de-dos-colas-6">Caso A Prueba de dos colas</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-b-prueba-de-cola-inferior-5" id="toc-caso-b-prueba-de-cola-inferior-5">Caso B Prueba de cola inferior</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-c-prueba-de-cola-superior-4" id="toc-caso-c-prueba-de-cola-superior-4">Caso C Prueba de cola superior</a></li>
</ul></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejemplo-8" id="toc-ejemplo-8"><span class="toc-section-number">10.5</span> Ejemplo</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejemplo-en-r-studio-7" id="toc-ejemplo-en-r-studio-7"><span class="toc-section-number">10.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejercicios-6" id="toc-ejercicios-6"><span class="toc-section-number">10.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-para-más-de-dos-muestras.html#prueba-para-más-de-dos-muestras" id="toc-prueba-para-más-de-dos-muestras"><span class="toc-section-number">11</span> Prueba para más de dos Muestras</a>
<ul>
<li><a href="prueba-para-más-de-dos-muestras.html#datos-9" id="toc-datos-9"><span class="toc-section-number">11.1</span> Datos</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#hipótesis-8" id="toc-hipótesis-8"><span class="toc-section-number">11.2</span> Hipótesis</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#estadístico-de-prueba-8" id="toc-estadístico-de-prueba-8"><span class="toc-section-number">11.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#regla-de-decisión-20" id="toc-regla-de-decisión-20"><span class="toc-section-number">11.4</span> Regla de decisión</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#comparación-múltiple" id="toc-comparación-múltiple"><span class="toc-section-number">11.5</span> Comparación múltiple</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#ejemplo-9" id="toc-ejemplo-9"><span class="toc-section-number">11.6</span> Ejemplo</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#ejemplo-en-r-studio-8" id="toc-ejemplo-en-r-studio-8"><span class="toc-section-number">11.7</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="#part-tablas-de-contingencia" id="toc-part-tablas-de-contingencia">(PART) Tablas de Contingencia</a></li>
<li><a href="introducción-3.html#introducción-3" id="toc-introducción-3">Introducción</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#tablas-de-contingencia-de-2x2" id="toc-tablas-de-contingencia-de-2x2"><span class="toc-section-number">12</span> Tablas de Contingencia de 2x2</a>
<ul>
<li><a href="tablas-de-contingencia-de-2x2.html#datos-10" id="toc-datos-10"><span class="toc-section-number">12.1</span> Datos</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#supuestos-9" id="toc-supuestos-9"><span class="toc-section-number">12.2</span> Supuestos</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#estadístico-de-prueba-9" id="toc-estadístico-de-prueba-9"><span class="toc-section-number">12.3</span> Estadístico de Prueba</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#hipótesis-9" id="toc-hipótesis-9"><span class="toc-section-number">12.4</span> Hipótesis</a>
<ul>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-a-prueba-de-dos-colas-7" id="toc-caso-a-prueba-de-dos-colas-7">Caso A Prueba de dos colas</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-b-prueba-de-cola-inferior-6" id="toc-caso-b-prueba-de-cola-inferior-6">Caso B Prueba de cola inferior</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-c-prueba-de-cola-superior-5" id="toc-caso-c-prueba-de-cola-superior-5">Caso C Prueba de cola superior</a></li>
</ul></li>
<li><a href="tablas-de-contingencia-de-2x2.html#ejemplo-10" id="toc-ejemplo-10"><span class="toc-section-number">12.5</span> Ejemplo</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#ejemplo-en-r-studio-9" id="toc-ejemplo-en-r-studio-9"><span class="toc-section-number">12.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="prueba-de-independencia.html#prueba-de-independencia" id="toc-prueba-de-independencia"><span class="toc-section-number">13</span> Prueba de Independencia</a>
<ul>
<li><a href="prueba-de-independencia.html#datos-11" id="toc-datos-11"><span class="toc-section-number">13.1</span> Datos</a></li>
<li><a href="prueba-de-independencia.html#supuestos-10" id="toc-supuestos-10"><span class="toc-section-number">13.2</span> Supuestos</a></li>
<li><a href="prueba-de-independencia.html#estadístico-de-prueba-10" id="toc-estadístico-de-prueba-10"><span class="toc-section-number">13.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-independencia.html#hipótesis-10" id="toc-hipótesis-10"><span class="toc-section-number">13.4</span> Hipótesis</a></li>
<li><a href="prueba-de-independencia.html#ejercicio" id="toc-ejercicio"><span class="toc-section-number">13.5</span> Ejercicio</a></li>
<li><a href="prueba-de-independencia.html#ejemplo-en-r-studio-10" id="toc-ejemplo-en-r-studio-10"><span class="toc-section-number">13.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-independencia.html#ejercicios-7" id="toc-ejercicios-7"><span class="toc-section-number">13.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#tablas-de-contingecia-de-r-times-c" id="toc-tablas-de-contingecia-de-r-times-c"><span class="toc-section-number">14</span> Tablas de Contingecia de <span class="math inline">\(r \times c\)</span></a>
<ul>
<li><a href="tablas-de-contingecia-de-r-times-c.html#prueba-de-chi2-para-tablas-de-contingencia-proporciones" id="toc-prueba-de-chi2-para-tablas-de-contingencia-proporciones">Prueba de <span class="math inline">\(\chi^2\)</span> para Tablas de Contingencia (Proporciones)</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#datos-12" id="toc-datos-12"><span class="toc-section-number">14.1</span> Datos</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#supuestos-11" id="toc-supuestos-11"><span class="toc-section-number">14.2</span> Supuestos</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#estadístico-de-prueba-11" id="toc-estadístico-de-prueba-11"><span class="toc-section-number">14.3</span> Estadístico de Prueba</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#hipótesis-11" id="toc-hipótesis-11"><span class="toc-section-number">14.4</span> Hipótesis</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejercicio-1" id="toc-ejercicio-1"><span class="toc-section-number">14.5</span> Ejercicio</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejemplo-en-r-studio-11" id="toc-ejemplo-en-r-studio-11"><span class="toc-section-number">14.6</span> Ejemplo en R-Studio</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejercicios-8" id="toc-ejercicios-8"><span class="toc-section-number">14.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-la-mediana.html#prueba-de-la-mediana" id="toc-prueba-de-la-mediana"><span class="toc-section-number">15</span> Prueba de la Mediana</a>
<ul>
<li><a href="prueba-de-la-mediana.html#datos-13" id="toc-datos-13"><span class="toc-section-number">15.1</span> Datos</a></li>
<li><a href="prueba-de-la-mediana.html#supuestos-12" id="toc-supuestos-12"><span class="toc-section-number">15.2</span> Supuestos</a></li>
<li><a href="prueba-de-la-mediana.html#estadístico-de-prueba-12" id="toc-estadístico-de-prueba-12"><span class="toc-section-number">15.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-la-mediana.html#hipótesis-12" id="toc-hipótesis-12"><span class="toc-section-number">15.4</span> Hipótesis</a></li>
<li><a href="prueba-de-la-mediana.html#comparación-múltiple-1" id="toc-comparación-múltiple-1"><span class="toc-section-number">15.5</span> Comparación Múltiple</a>
<ul>
<li><a href="prueba-de-la-mediana.html#ejercicio-2" id="toc-ejercicio-2"><span class="toc-section-number">15.5.1</span> Ejercicio</a></li>
</ul></li>
<li><a href="prueba-de-la-mediana.html#ejemplo-en-r-studio-12" id="toc-ejemplo-en-r-studio-12"><span class="toc-section-number">15.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-la-mediana.html#ejercicios-9" id="toc-ejercicios-9"><span class="toc-section-number">15.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="#part-bondad-de-ajuste" id="toc-part-bondad-de-ajuste">(PART) Bondad de Ajuste</a></li>
<li><a href="introducción-4.html#introducción-4" id="toc-introducción-4">Introducción</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#prueba-de-la-ji-cuadrada" id="toc-prueba-de-la-ji-cuadrada"><span class="toc-section-number">16</span> Prueba de la Ji-cuadrada</a>
<ul>
<li><a href="prueba-de-la-ji-cuadrada.html#datos-14" id="toc-datos-14"><span class="toc-section-number">16.1</span> Datos</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#hipótesis-13" id="toc-hipótesis-13"><span class="toc-section-number">16.2</span> Hipótesis</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#estadístico-de-prueba-13" id="toc-estadístico-de-prueba-13"><span class="toc-section-number">16.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejemplo-11" id="toc-ejemplo-11"><span class="toc-section-number">16.4</span> Ejemplo</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejemplo-en-r-studio-13" id="toc-ejemplo-en-r-studio-13"><span class="toc-section-number">16.5</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejercicios-10" id="toc-ejercicios-10"><span class="toc-section-number">16.6</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#prueba-kolmogorov" id="toc-prueba-kolmogorov"><span class="toc-section-number">17</span> Prueba Kolmogorov</a>
<ul>
<li><a href="prueba-kolmogorov.html#datos-15" id="toc-datos-15"><span class="toc-section-number">17.1</span> Datos</a></li>
<li><a href="prueba-kolmogorov.html#supuestos-13" id="toc-supuestos-13"><span class="toc-section-number">17.2</span> Supuestos</a></li>
<li><a href="prueba-kolmogorov.html#estadístico-de-prueba-14" id="toc-estadístico-de-prueba-14"><span class="toc-section-number">17.3</span> Estadístico de Prueba</a>
<ul>
<li><a href="prueba-kolmogorov.html#caso-a-prueba-de-2-colas" id="toc-caso-a-prueba-de-2-colas">Caso A (Prueba de 2 colas)</a></li>
<li><a href="prueba-kolmogorov.html#caso-b-prueba-de-1-cola" id="toc-caso-b-prueba-de-1-cola">Caso B (Prueba de 1 cola)</a></li>
<li><a href="prueba-kolmogorov.html#caso-c-prueba-de-1-cola" id="toc-caso-c-prueba-de-1-cola">Caso C (Prueba de 1 cola)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#hipótesis-14" id="toc-hipótesis-14"><span class="toc-section-number">17.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-kolmogorov.html#caso-a-prueba-de-2-colas-1" id="toc-caso-a-prueba-de-2-colas-1">Caso A (Prueba de 2 colas)</a></li>
<li><a href="prueba-kolmogorov.html#caso-b-prueba-de-1-cola-1" id="toc-caso-b-prueba-de-1-cola-1">Caso B (Prueba de 1 cola)</a></li>
<li><a href="prueba-kolmogorov.html#caso-c-prueba-de-1-cola-1" id="toc-caso-c-prueba-de-1-cola-1">Caso C (Prueba de 1 cola)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#ejemplo-12" id="toc-ejemplo-12"><span class="toc-section-number">17.5</span> Ejemplo</a></li>
<li><a href="prueba-kolmogorov.html#ejemplo-en-r-studio-14" id="toc-ejemplo-en-r-studio-14"><span class="toc-section-number">17.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-kolmogorov.html#otro-ejemplo-en-r" id="toc-otro-ejemplo-en-r"><span class="toc-section-number">17.7</span> Otro ejemplo en R</a></li>
<li><a href="prueba-kolmogorov.html#ejercicios-11" id="toc-ejercicios-11"><span class="toc-section-number">17.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-kolmogorov-smirnov.html#prueba-kolmogorov-smirnov" id="toc-prueba-kolmogorov-smirnov"><span class="toc-section-number">18</span> Prueba Kolmogorov-Smirnov</a>
<ul>
<li><a href="prueba-kolmogorov-smirnov.html#hipótesis-15" id="toc-hipótesis-15"><span class="toc-section-number">18.1</span> Hipótesis</a>
<ul>
<li><a href="prueba-kolmogorov-smirnov.html#caso-a-prueba-de-2-colas-2" id="toc-caso-a-prueba-de-2-colas-2"><span class="toc-section-number">18.1.1</span> Caso A (Prueba de 2 colas)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov-smirnov.html#ejemplo-13" id="toc-ejemplo-13"><span class="toc-section-number">18.2</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-lilliefors-para-normalidad.html#prueba-lilliefors-para-normalidad" id="toc-prueba-lilliefors-para-normalidad"><span class="toc-section-number">19</span> Prueba Lilliefors para Normalidad</a>
<ul>
<li><a href="prueba-lilliefors-para-normalidad.html#datos-16" id="toc-datos-16"><span class="toc-section-number">19.1</span> Datos</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#supuestos-14" id="toc-supuestos-14"><span class="toc-section-number">19.2</span> Supuestos</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#hipótesis-16" id="toc-hipótesis-16"><span class="toc-section-number">19.3</span> Hipótesis</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#estadístico-de-prueba-15" id="toc-estadístico-de-prueba-15"><span class="toc-section-number">19.4</span> Estadístico de Prueba</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejemplo-14" id="toc-ejemplo-14"><span class="toc-section-number">19.5</span> Ejemplo</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejemplo-en-r-studio-15" id="toc-ejemplo-en-r-studio-15"><span class="toc-section-number">19.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejercicios-12" id="toc-ejercicios-12"><span class="toc-section-number">19.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="pueba-de-lilliefors-exponencial.html#pueba-de-lilliefors-exponencial" id="toc-pueba-de-lilliefors-exponencial"><span class="toc-section-number">20</span> Pueba de Lilliefors Exponencial</a>
<ul>
<li><a href="pueba-de-lilliefors-exponencial.html#datos-17" id="toc-datos-17"><span class="toc-section-number">20.1</span> Datos</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#supuestos-15" id="toc-supuestos-15"><span class="toc-section-number">20.2</span> Supuestos</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#hipótesis-17" id="toc-hipótesis-17"><span class="toc-section-number">20.3</span> Hipótesis</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#estadistico-de-prueba" id="toc-estadistico-de-prueba"><span class="toc-section-number">20.4</span> Estadistico de Prueba</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejemplo-15" id="toc-ejemplo-15"><span class="toc-section-number">20.5</span> Ejemplo</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejemplo-en-r-studio-16" id="toc-ejemplo-en-r-studio-16"><span class="toc-section-number">20.6</span> Ejemplo en R-Studio</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejercicios-13" id="toc-ejercicios-13"><span class="toc-section-number">20.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#prueba-anderson-darling" id="toc-prueba-anderson-darling"><span class="toc-section-number">21</span> Prueba Anderson-Darling</a>
<ul>
<li><a href="prueba-anderson-darling.html#datos-18" id="toc-datos-18"><span class="toc-section-number">21.1</span> Datos</a></li>
<li><a href="prueba-anderson-darling.html#supuestos-16" id="toc-supuestos-16"><span class="toc-section-number">21.2</span> Supuestos</a></li>
<li><a href="prueba-anderson-darling.html#hipótesis-18" id="toc-hipótesis-18"><span class="toc-section-number">21.3</span> Hipótesis</a>
<ul>
<li><a href="prueba-anderson-darling.html#caso-a-prueba-de-2-colas-solo-será-este-caso" id="toc-caso-a-prueba-de-2-colas-solo-será-este-caso">Caso A (Prueba de 2 colas) Solo será este caso</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#estadístico-de-prueba-16" id="toc-estadístico-de-prueba-16"><span class="toc-section-number">21.4</span> Estadístico de Prueba</a></li>
<li><a href="prueba-anderson-darling.html#regla-de-decisión-34" id="toc-regla-de-decisión-34"><span class="toc-section-number">21.5</span> Regla de Decisión</a>
<ul>
<li><a href="prueba-anderson-darling.html#ejemplo-16" id="toc-ejemplo-16"><span class="toc-section-number">21.5.1</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#ejemplo-en-r-studio-17" id="toc-ejemplo-en-r-studio-17"><span class="toc-section-number">21.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="otras-estadísticas.html#otras-estadísticas" id="toc-otras-estadísticas"><span class="toc-section-number">22</span> Otras estadísticas</a>
<ul>
<li><a href="otras-estadísticas.html#mas-ejercicios" id="toc-mas-ejercicios"><span class="toc-section-number">22.1</span> Mas ejercicios</a></li>
</ul></li>
<li><a href="#part-regresión-lineal-simple" id="toc-part-regresión-lineal-simple">(PART) Regresión Lineal Simple</a></li>
<li><a href="introducción-5.html#introducción-5" id="toc-introducción-5">Introducción</a></li>
<li><a href="modelo-con-intercepto.html#modelo-con-intercepto" id="toc-modelo-con-intercepto"><span class="toc-section-number">23</span> Modelo con intercepto</a>
<ul>
<li><a href="modelo-con-intercepto.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo"><span class="toc-section-number">23.1</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-con-intercepto.html#propiedades-de-los-estimadores" id="toc-propiedades-de-los-estimadores"><span class="toc-section-number">23.2</span> Propiedades de los estimadores</a></li>
</ul></li>
<li><a href="modelo-sin-intercepto.html#modelo-sin-intercepto" id="toc-modelo-sin-intercepto"><span class="toc-section-number">24</span> Modelo sin intercepto</a>
<ul>
<li><a href="modelo-sin-intercepto.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-1" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-1"><span class="toc-section-number">24.1</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-sin-intercepto.html#propiedades-de-los-estimadores-1" id="toc-propiedades-de-los-estimadores-1"><span class="toc-section-number">24.2</span> Propiedades de los estimadores</a>
<ul>
<li><a href="modelo-sin-intercepto.html#ejemplo-en-r-studio-18" id="toc-ejemplo-en-r-studio-18"><span class="toc-section-number">24.2.1</span> Ejemplo en R-Studio</a></li>
</ul></li>
</ul></li>
<li><a href="intervalos-de-confianza-1.html#intervalos-de-confianza-1" id="toc-intervalos-de-confianza-1"><span class="toc-section-number">25</span> Intervalos de confianza</a>
<ul>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-beta_0" id="toc-intervalo-para-beta_0"><span class="toc-section-number">25.1</span> Intervalo para <span class="math inline">\(\beta_{0}\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-beta_1" id="toc-intervalo-para-beta_1"><span class="toc-section-number">25.2</span> Intervalo para <span class="math inline">\(\beta_{1}\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-sigma2" id="toc-intervalo-para-sigma2"><span class="toc-section-number">25.3</span> Intervalo para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-el-valor-esperado-y" id="toc-intervalo-para-el-valor-esperado-y"><span class="toc-section-number">25.4</span> Intervalo para el valor esperado <span class="math inline">\(y\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-de-predicción" id="toc-intervalo-de-predicción"><span class="toc-section-number">25.5</span> Intervalo de predicción</a>
<ul>
<li><a href="intervalos-de-confianza-1.html#ejemplo-17" id="toc-ejemplo-17"><span class="toc-section-number">25.5.1</span> Ejemplo</a></li>
</ul></li>
</ul></li>
<li><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis" id="toc-pruebas-de-hipótesis"><span class="toc-section-number">26</span> Pruebas de hipótesis</a>
<ul>
<li><a href="pruebas-de-hipótesis.html#pruebas-para-beta_0" id="toc-pruebas-para-beta_0"><span class="toc-section-number">26.1</span> Pruebas para <span class="math inline">\(\beta_{0}\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#prueba-para-beta_1" id="toc-prueba-para-beta_1"><span class="toc-section-number">26.2</span> Prueba para <span class="math inline">\(\beta_{1}\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#prueba-para-sigma2" id="toc-prueba-para-sigma2"><span class="toc-section-number">26.3</span> Prueba para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#análisis-de-la-varianza-anova" id="toc-análisis-de-la-varianza-anova"><span class="toc-section-number">26.4</span> Análisis de la varianza (ANOVA)</a></li>
<li><a href="pruebas-de-hipótesis.html#coeficiente-de-determinación" id="toc-coeficiente-de-determinación"><span class="toc-section-number">26.5</span> Coeficiente de determinación</a></li>
<li><a href="pruebas-de-hipótesis.html#propiedades-de-r2" id="toc-propiedades-de-r2"><span class="toc-section-number">26.6</span> Propiedades de <span class="math inline">\(R^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#relación-r2-y-la-correlación-de-pearson" id="toc-relación-r2-y-la-correlación-de-pearson"><span class="toc-section-number">26.7</span> Relación <span class="math inline">\(R^2\)</span> y la correlación de Pearson</a>
<ul>
<li><a href="pruebas-de-hipótesis.html#ejemplo-18" id="toc-ejemplo-18"><span class="toc-section-number">26.7.1</span> Ejemplo</a></li>
</ul></li>
</ul></li>
<li><a href="validación-de-supuestos.html#validación-de-supuestos" id="toc-validación-de-supuestos"><span class="toc-section-number">27</span> Validación de supuestos</a>
<ul>
<li><a href="validación-de-supuestos.html#análisis-de-residuales" id="toc-análisis-de-residuales"><span class="toc-section-number">27.1</span> Análisis de residuales</a></li>
<li><a href="validación-de-supuestos.html#supuesto-de-normalidad" id="toc-supuesto-de-normalidad"><span class="toc-section-number">27.2</span> Supuesto de normalidad</a>
<ul>
<li><a href="validación-de-supuestos.html#validación-del-supuesto-de-normalidad" id="toc-validación-del-supuesto-de-normalidad"><span class="toc-section-number">27.2.1</span> Validación del supuesto de normalidad</a></li>
</ul></li>
<li><a href="validación-de-supuestos.html#supuesto-de-linealidad" id="toc-supuesto-de-linealidad"><span class="toc-section-number">27.3</span> Supuesto de linealidad</a></li>
<li><a href="validación-de-supuestos.html#supuesto-de-homocedasticidad" id="toc-supuesto-de-homocedasticidad"><span class="toc-section-number">27.4</span> Supuesto de homocedasticidad</a>
<ul>
<li><a href="validación-de-supuestos.html#prueba-de-breusch-pagan" id="toc-prueba-de-breusch-pagan"><span class="toc-section-number">27.4.1</span> Prueba de Breusch-Pagan</a></li>
<li><a href="validación-de-supuestos.html#prueba-de-white" id="toc-prueba-de-white"><span class="toc-section-number">27.4.2</span> Prueba de White</a></li>
<li><a href="validación-de-supuestos.html#ejemplo-19" id="toc-ejemplo-19"><span class="toc-section-number">27.4.3</span> Ejemplo</a></li>
</ul></li>
<li><a href="validación-de-supuestos.html#valores-outlier-e-influyentes" id="toc-valores-outlier-e-influyentes"><span class="toc-section-number">27.5</span> Valores outlier e influyentes</a>
<ul>
<li><a href="validación-de-supuestos.html#valores-outlier" id="toc-valores-outlier"><span class="toc-section-number">27.5.1</span> Valores outlier</a></li>
<li><a href="validación-de-supuestos.html#valores-influentes" id="toc-valores-influentes"><span class="toc-section-number">27.5.2</span> Valores influentes</a></li>
</ul></li>
</ul></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#modelo-de-regresión-lineal-múltiple" id="toc-modelo-de-regresión-lineal-múltiple"><span class="toc-section-number">28</span> Modelo de regresión lineal múltiple</a>
<ul>
<li><a href="modelo-de-regresión-lineal-múltiple.html#introducción-6" id="toc-introducción-6"><span class="toc-section-number">28.1</span> Introducción</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#modelo-de-regresión-lineal-múltiple-1" id="toc-modelo-de-regresión-lineal-múltiple-1"><span class="toc-section-number">28.2</span> Modelo de regresión lineal múltiple</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-2" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-2"><span class="toc-section-number">28.3</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#estimación-por-máxima-verosimilitud" id="toc-estimación-por-máxima-verosimilitud"><span class="toc-section-number">28.4</span> Estimación por máxima verosimilitud</a></li>
</ul></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-confianza-2" id="toc-intervalos-de-confianza-2"><span class="toc-section-number">29</span> Intervalos de confianza</a>
<ul>
<li><a href="intervalos-de-confianza-2.html#intervalo-para-beta_j" id="toc-intervalo-para-beta_j"><span class="toc-section-number">29.1</span> Intervalo para <span class="math inline">\(\beta_{j}\)</span></a></li>
<li><a href="intervalos-de-confianza-2.html#intervalo-para-sigma2-1" id="toc-intervalo-para-sigma2-1"><span class="toc-section-number">29.2</span> Intervalo para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-la-respuesta-media" id="toc-intervalos-de-la-respuesta-media"><span class="toc-section-number">29.3</span> Intervalos de la respuesta media</a></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-predicción" id="toc-intervalos-de-predicción"><span class="toc-section-number">29.4</span> Intervalos de predicción</a></li>
</ul></li>
<li><a href="pruebas-de-hipótesis-1.html#pruebas-de-hipótesis-1" id="toc-pruebas-de-hipótesis-1"><span class="toc-section-number">30</span> Pruebas de hipótesis</a>
<ul>
<li><a href="pruebas-de-hipótesis-1.html#región-de-rechazo-para-beta_j" id="toc-región-de-rechazo-para-beta_j"><span class="toc-section-number">30.1</span> Región de rechazo para <span class="math inline">\(\beta_{j}\)</span></a></li>
<li><a href="pruebas-de-hipótesis-1.html#prueba-para-sigma2-1" id="toc-prueba-para-sigma2-1"><span class="toc-section-number">30.2</span> Prueba para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis-1.html#análisis-de-la-varianza-anova-1" id="toc-análisis-de-la-varianza-anova-1"><span class="toc-section-number">30.3</span> Análisis de la varianza (ANOVA)</a></li>
<li><a href="pruebas-de-hipótesis-1.html#coeficiente-de-determinación-2" id="toc-coeficiente-de-determinación-2"><span class="toc-section-number">30.4</span> Coeficiente de determinación</a></li>
<li><a href="pruebas-de-hipótesis-1.html#r2-ajustado" id="toc-r2-ajustado"><span class="toc-section-number">30.5</span> <span class="math inline">\(R^2\)</span> ajustado</a></li>
</ul></li>
<li><a href="validación-de-supuestos-1.html#validación-de-supuestos-1" id="toc-validación-de-supuestos-1"><span class="toc-section-number">31</span> Validación de supuestos</a>
<ul>
<li><a href="validación-de-supuestos-1.html#supuesto-de-multicolinealidad" id="toc-supuesto-de-multicolinealidad"><span class="toc-section-number">31.1</span> Supuesto de multicolinealidad</a></li>
<li><a href="validación-de-supuestos-1.html#detección-de-multicolinealidad" id="toc-detección-de-multicolinealidad"><span class="toc-section-number">31.2</span> Detección de multicolinealidad</a></li>
<li><a href="validación-de-supuestos-1.html#ejemplo-20" id="toc-ejemplo-20"><span class="toc-section-number">31.3</span> Ejemplo</a></li>
</ul></li>
<li><a href="apéndice.html#apéndice" id="toc-apéndice"><span class="toc-section-number">32</span> Apéndice</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Hecho con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos no paramétricos y de Regresión</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelo-de-regresión-lineal-múltiple" class="section level1" number="28">
<h1><span class="header-section-number">Capítulo 28</span> Modelo de regresión lineal múltiple</h1>
<p>Antes de empezar, el siguiente tema “Regresión Lineal Múltiple”, queremos hacer referencia que fue obtenido de tesis: “Apoyo a la docencia” <span class="citation">Omar (<a href="#ref-Tesisdelicenciatura2019Estadistica" role="doc-biblioref">2019</a>)</span>.</p>
<div id="introducción-6" class="section level2" number="28.1">
<h2><span class="header-section-number">28.1</span> Introducción</h2>
<p>El modelo de regresión lineal simple ajusta una variable explicativa a una variable respuesta; Por su parte, el <strong>Modelo de regresión lineal múltiple</strong> busca hallar el mejor ajuste con dos o más variables regresoras. Es decir, la variable respuesta <span class="math inline">\(\underline{Y}\)</span> depende de <span class="math inline">\(k\)</span> regresores de la forma:</p>
<p><span class="math display">\[
\underline{Y}=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots +\beta_{k}x_{k}+\epsilon
\]</span></p>
<p>En primera instancia no parece ser un gran cambio, sin embargo, es de gran importancia ya que de esta forma se puede estimar de una mejor manera un evento aleatorio, pues en general, un suceso no depende de sólo una acción o variable, sino que es resultado de una serie de diversos eventos o variables.</p>
<p>Es importante mencionar que en un modelo de regresión múltiple se deja de ajustar una línea recta a los datos, en cambio se ajusta un hiperplano.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;trees&quot;</span>)</span>
<span id="cb276-2"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;scatterplot3d&quot;</span>)</span>
<span id="cb276-3"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-3" aria-hidden="true" tabindex="-1"></a>s3d <span class="ot">&lt;-</span> <span class="fu">scatterplot3d</span>(trees, <span class="at">type =</span> <span class="st">&quot;h&quot;</span>, <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb276-4"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">angle=</span><span class="dv">55</span>, <span class="at">pch =</span> <span class="dv">16</span>, <span class="at">xlab =</span> <span class="st">&quot;Diametro del arbol&quot;</span>,<span class="at">ylab =</span> <span class="st">&quot;Altura del arbol&quot;</span>, <span class="at">zlab=</span><span class="st">&quot;Volumen&quot;</span>)</span>
<span id="cb276-5"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-5" aria-hidden="true" tabindex="-1"></a>my.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(trees<span class="sc">$</span>Volume <span class="sc">~</span> trees<span class="sc">$</span>Girth <span class="sc">+</span> trees<span class="sc">$</span>Height)</span>
<span id="cb276-6"><a href="modelo-de-regresión-lineal-múltiple.html#cb276-6" aria-hidden="true" tabindex="-1"></a>s3d<span class="sc">$</span><span class="fu">plane3d</span>(my.lm)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-125-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>El “scatterplot” de arriba, se realizó con la base precargada en <span class="math inline">\(R\)</span>, <span class="math inline">\(&quot;trees&quot;\)</span>, los datos que componen la muestra se encuentran en un vector de dimensión 3, la cual busca relacionar la variable <span class="math inline">\(\underline{Y}\)</span>, con dos variables explicativas <span class="math inline">\(X_{1}\)</span> y <span class="math inline">\(X_{2}\)</span>, en este caso, la variable <span class="math inline">\(\underline{Y}\)</span> hace referencia al volumen de un árbol y la variable <span class="math inline">\(X_{1}\)</span> hace referencia al diámetro del tronco del árbol y <span class="math inline">\(X_{2}\)</span> denota la altura del árbol, se observa que existe una tendencia, la cual es representada mediante el hiperplano de regresión marcado, en la cual a menor diámetro y menor altura, el volumen del árbol tiende a disminuir.</p>
<p>Debido a que se trabaja con cierto error <span class="math inline">\(\epsilon\)</span> en el ajuste de la regresión, es conveniente suponer que se cumplen lo siguientes supuestos:</p>
<p><strong>Definición 3.1</strong> (Supuestos del modelo de regresión múltiple)</p>
<p>El error <span class="math inline">\(\epsilon_{i}\)</span> en el modelo de regresión lineal múltiple cumple:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{E}[\epsilon_{i}]=0.\)</span></p></li>
<li><p><span class="math inline">\(Var(\epsilon_{i})=\sigma^2.\)</span></p></li>
<li><p><span class="math inline">\(Cov(\epsilon_{i},\epsilon_{j})=0, \ \ i \neq j \ \ \forall \ \ i= 1,2,\ldots,n; \ \ j= 1,2,\ldots,n.\)</span></p></li>
</ul>
<p>Al cumplirse estos supuestos es posible calcular la esperanza y varianza de la variable respuesta <span class="math inline">\(\underline{Y}\)</span> dado un conjunto de valores <span class="math inline">\(x_{1},x_{2},\ldots,x_{k}.\)</span></p>
<p><strong>Teorema 3.1</strong> Sea una variable de interés <span class="math inline">\(\underline{Y}\)</span>, llamada <strong>dependiente</strong>, relacionada con dos o más variables explicativas o también llamadas regresoras <span class="math inline">\(x_{1},x_{2},\ldots,x_{k}\)</span>,
entonces:</p>
<p><strong>a)</strong> <span class="math inline">\(\mathbf{E}[\underline{Y}]= \beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots + \beta_{k}x_{k}.\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(Var(\underline{Y})= \sigma^2.\)</span></p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong> Para la esperanza de <span class="math inline">\(\underline{Y}\)</span> se tiene:</p>
<p><span class="math display">\[\mathbf{E}[\underline{Y}]=\mathbf{E}[\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots +\beta_{k}x_{k}+\epsilon].\]</span>
La estimación es sobre <span class="math inline">\(\underline{Y},\)</span>
como <span class="math inline">\(\beta_{0},\beta_{1},\beta_{2},\ldots,\beta_{k}\)</span> son constantes; <span class="math inline">\(x_{1},x_{2}, \ldots,x_{k}\)</span> son los valores dados, por lo que:</p>
<p><span class="math display">\[\mathbf{E}[\underline{Y}]=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots +\beta_{k}x_{k}+\mathbf{E}[\epsilon].\]</span></p>
<p><span class="math display">\[=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots +\beta_{k}x_{k}+0\]</span>
<span class="math display">\[\therefore \mathbf{E}[\underline{Y}]= \beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots + \beta_{k}x_{k}. \blacksquare\]</span></p>
<p><strong>b)</strong> Para la varianza de <span class="math inline">\(\underline{Y}\)</span> se tiene:</p>
<p><span class="math display">\[Var(\underline{Y})=Var\left( \beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+ \ldots + \beta_{k}x_{k}+ \epsilon\right).\]</span>
La estimación es sobre <span class="math inline">\(\underline{Y}\)</span>, <span class="math inline">\(\beta_{0},\beta_{1},\beta_{2},\ldots,\beta_{k}\)</span> son constantes; <span class="math inline">\(x_{1},x_{2},\ldots,x_{k}\)</span> son valores dados, por lo que cumple que:</p>
<p><span class="math display">\[Var(\underline{Y})=0+0+0+\ldots+0+Var(\epsilon)\]</span>
<span class="math display">\[\therefore Var(\underline{Y})=\sigma^2.\blacksquare\]</span></p>
</div>
<div id="modelo-de-regresión-lineal-múltiple-1" class="section level2" number="28.2">
<h2><span class="header-section-number">28.2</span> Modelo de regresión lineal múltiple</h2>
<p>El objetivo del modelo de regresión lineal múltiple consiste en modelar <span class="math inline">\(\underline{Y}\)</span> a través de <span class="math inline">\(k\)</span> variables regresoras en <span class="math inline">\(n\)</span> observaciones independientes. Es decir, se tiene el siguiente modelo:</p>
<p><span class="math display">\[
\begin{array}{ c c c c c c c c c c c c c }
Y_{1}  &amp; = &amp; \beta_{0} &amp; + &amp; \beta_{1}x_{11}&amp; +&amp; \beta_{2}x_{12} &amp; +&amp; \cdots &amp; + &amp; \beta_{k}x_{1k} &amp; + &amp; \epsilon_{1}  \\
Y_{2}  &amp; = &amp; \beta_{0} &amp; + &amp; \beta_{1}x_{21}&amp; +&amp; \beta_{2}x_{22} &amp; +&amp; \cdots &amp; + &amp; \beta_{k}x_{2k} &amp; + &amp; \epsilon_{2}  \\
\vdots  &amp;  &amp; \vdots &amp;  &amp; \vdots&amp; &amp; \vdots &amp; &amp; \vdots &amp; &amp; \vdots &amp;  &amp; \vdots  \\
Y_{n}  &amp; = &amp; \beta_{0} &amp; + &amp; \beta_{1}x_{n1}&amp; +&amp; \beta_{2}x_{n2} &amp; +&amp; \cdots &amp; + &amp; \beta_{k}x_{nk} &amp; + &amp; \epsilon_{n}  \\
\end{array}
\]</span></p>
<p>El anterior conjunto de igualdades puede ser denotado matricialmente mediante la siguiente igualdad:</p>
<p><span class="math display">\[\underline{Y}=X\underline{\beta}+\underline{\epsilon}\]</span></p>
<p>donde:
<span class="math display">\[
\underline{Y}=
\left(
\begin{array}{c}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}\\
\end{array}
\right),\ \ \ \  X=
\left(
\begin{array}{c c c c c}
1      &amp; x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1k}\\
1      &amp; x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1      &amp; x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{nk}\\
\end{array}
\right)
\]</span>
<span class="math display">\[
\underline{\beta}=
\left(
\begin{array}{c}
\beta_{0} \\
\beta_{1} \\
\vdots \\
\beta_{k}\\
\end{array}
\right),\ \ \ \  \epsilon=
\left(
\begin{array}{c}
\epsilon_{1} \\
\epsilon_{2} \\
\vdots \\
\epsilon_{n}\\
\end{array}
\right)
\]</span>
Sustituyendo en la ecuación anterior, se observa que el modelo de regresión multiple puede ser visto como:
<span class="math display">\[
\left(
\begin{array}{c}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}\\
\end{array}
\right)=
\left(
\begin{array}{c c c c c}
1      &amp; x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1k}\\
1      &amp; x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1      &amp; x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{nk}\\
\end{array}
\right)
\left(
\begin{array}{c}
\beta_{0} \\
\beta_{1} \\
\vdots \\
\beta_{k}\\
\end{array}
\right) +
\left(
\begin{array}{c}
\epsilon_{1} \\
\epsilon_{2} \\
\vdots \\
\epsilon_{n}\\
\end{array}
\right)
\]</span></p>
<p>La dimensión de las matrices señaladas anteriormente se mencionan en el siguiente recuadro:</p>
<p><span class="math display">\[
\begin{array}{|c|c|}
\hline
Matriz &amp; Dimensión \\
\hline
\underline{Y}        &amp; n \times 1 \\
X                   &amp; n \times (k+1) \\
\underline{\epsilon} &amp; n \times 1 \\
\underline{\beta}    &amp; (k+1) \times 1 \\
\hline
\end{array}
\]</span></p>
<p>Finalmente para definir correctamente el modelo es necesario realizar las siguientes suposiciones acerca de las matrices del modelo de regresión lineal múltiple.</p>
<p><strong>Definición 3.2</strong> Sea <span class="math inline">\(X\)</span> la denominada <span class="math inline">\(matriz \ diseño\)</span> entonces satisface que:</p>
<ul>
<li><span class="math inline">\(X_{n \times (k+1)}\)</span> es el rango completo en la columna, es decir, <span class="math inline">\(X\)</span> es de rango <span class="math inline">\(k+1\)</span></li>
</ul>
<p>Éste supuesto es importante ya que satisface que <span class="math inline">\(k+1\leq n\)</span>, es decir, <strong>el máximo número de variables con el que se ajusta el modelo no puede ser superior al número de observaciones.</strong></p>
<p>De igual forma, observe que el supuesto de la varianza de los errores en la definición 3.1, puede reescribirse en forma matricial:</p>
<p><span class="math display">\[
Var(\epsilon)=
\left(
\begin{array}{c c c c c}
Var(\epsilon_{1}) &amp; Cov(\epsilon_{1},\epsilon_{2}) &amp; Cov(\epsilon_{1},\epsilon_{3}) &amp; \ldots &amp; Cov(\epsilon_{1},\epsilon_{ n})\\
Cov(\epsilon_{2},\epsilon_{1})&amp;Var(\epsilon_{2}) &amp; Cov(\epsilon_{2},\epsilon_{3}) &amp; \ldots &amp;Cov(\epsilon_{2},\epsilon_{n}) \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
Cov(\epsilon_{n},\epsilon_{1})   &amp; Cov(\epsilon_{n},\epsilon_{2}) &amp; Cov(\epsilon_{n},\epsilon_{3}) &amp; \ldots &amp; Var(\epsilon_{n})\\
\end{array}
\right)
\]</span></p>
<p>Por <strong>definición 3.1</strong>, <span class="math inline">\(Cov(\epsilon_{i},\epsilon_{j})=0 \ \ \ i\neq j\)</span></p>
<p><span class="math display">\[
Var(\epsilon)=
\left(
\begin{array}{c c c c c}
Var(\epsilon_{1}) &amp; 0 &amp; 0 &amp; \ldots &amp; 0 \\
0&amp;Var(\epsilon_{2}) &amp; 0 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; Var(\epsilon_{n})\\
\end{array}
\right)
\]</span></p>
<p>Por <strong>definición 3.1</strong>, <span class="math inline">\(Var(\epsilon_{i})=\sigma^2\)</span></p>
<p><span class="math display">\[
Var(\epsilon)=
\left(
\begin{array}{c c c c c}
\sigma^2 &amp; 0 &amp; 0 &amp; \ldots &amp; 0 \\
0&amp;\sigma^2 &amp; 0 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
0 &amp; 0 &amp; 0 &amp; \ldots &amp;\sigma^2  \\
\end{array}
\right)
\]</span></p>
<p><span class="math inline">\(\therefore Var(\epsilon)=\sigma^2 I_{n \times n}. \blacksquare\)</span></p>
</div>
<div id="estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-2" class="section level2" number="28.3">
<h2><span class="header-section-number">28.3</span> Estimación por mínimos cuadrados de los parámetros del modelo</h2>
<p>Es necesario dar una estimación de la intersección con el eje <span class="math inline">\(\underline{Y}\)</span>, las variables que conforman el hiperplano, es decir, <span class="math inline">\(\beta_{0},\beta_{1},\beta_{2},\ldots,\beta_{k}\)</span> respectivamente. La manera en la que se construyen a los estimadores es tal que la diferencia entre todos los valores observados y los valores estimados sea 0, es decir, a éstas diferencias se le conoce como <span class="math inline">\(\mathbf{residuales}\)</span>, muchos autores también hacen referencia a ellos como <span class="math inline">\(\mathbf{residuos}\)</span>.</p>
<p><strong>Definición 3.3</strong> (Residuales). Sea <span class="math inline">\(y_{i}\)</span> los valores observados, y sea <span class="math inline">\(\hat{y}_{i}\)</span> los valores ajustados de la forma <span class="math inline">\(\hat{y}_{i}=\hat{\beta_{0}}+\hat{\beta_{1}}x_{1i}+\hat{\beta_{2}}x_{2i}+ \ldots +\hat{\beta_{k}}x_{ki}\)</span>  para  <span class="math inline">\(\hat{\beta_{0}},\hat{\beta_{1}},\hat{\beta_{2}}, \ldots, \hat{\beta_{k}}\)</span>  dados,  entonces:</p>
<p><span class="math display">\[e_{i}=y_{i}-\hat{y_{i}} \ \ \ \ \ \ i=1, \ldots,n.\]</span>
Se les conoce como <strong>residuales.</strong></p>
<p>Para estimar los valores desconocidos <span class="math inline">\(\beta_{0},\beta_{1},\beta_{2},\ldots,\beta_{k}\)</span> se usa el <strong>método de mínimos cuadrados</strong>, el cual es similar al caso de regresión lineal simple, dicho método propone minimizar la suma de cuadrados de los residuales.</p>
<p>Antes de continuar es necesario ver algunos resultados importantes de equivalencia y notación.</p>
<p>De la <strong>definición 3.3</strong> se sabe que los valores esperados de <span class="math inline">\(y_{i}\)</span> pueden ser definidos como:</p>
<p><span class="math display">\[
\begin{array}{c}
\hat{y_{1}} \\
\hat{y_{2}} \\
\vdots \\
\hat{y_{n}}\\
\end{array}
\begin{array}{c c c c c c c c c c}
=&amp;\hat{\beta_{0}}&amp;+&amp;\hat{\beta_{1}} x_{11} &amp;+&amp; \hat{\beta_{2}}x_{12}&amp;+&amp; \ldots &amp;+&amp;\hat{\beta_{k}} x_{1k}\\
=&amp;\hat{\beta_{0}}&amp;+&amp;\hat{\beta_{1}} x_{21} &amp;+&amp; \hat{\beta_{2}}x_{22}&amp;+&amp; \ldots &amp;+&amp;\hat{\beta_{k}} x_{2k}\\
&amp;\vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \vdots\\
=&amp;\hat{\beta_{0}}&amp;+&amp;\hat{\beta_{1}} x_{n1} &amp;+&amp; \hat{\beta_{2}}x_{n2}&amp;+&amp; \ldots &amp;+&amp;\hat{\beta_{k}} x_{nk}\\
\end{array}
\]</span></p>
<p>La anterior ecuación puede ser descompuesta en forma matricial de la siguiente manera:</p>
<p><span class="math display">\[
\left(
\begin{array}{c}
\hat{y_{1}} \\
\hat{y_{2}} \\
\vdots \\
\hat{y_{n}}\\
\end{array}
\right)=
\left(
\begin{array}{c c c c c}
1      &amp; x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1k}\\
1      &amp; x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2k}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1      &amp; x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{nk}\\
\end{array}
\right)
\left(
\begin{array}{c}
\hat{\beta_{0}} \\
\hat{\beta_{1}} \\
\vdots \\
\hat{\beta_{k}}\\
\end{array}
\right)
\]</span></p>
<p>Por lo tanto, podemos renombrar a las matrices de acuerdo a los elementos que las conforman.</p>
<p>Se tiene la siguiente igualdad para los valores estimados <span class="math inline">\(\underline{\hat{Y}}.\)</span></p>
<p><span class="math display">\[\underline{\hat{Y}}=X \underline{\hat{\beta}}.\]</span></p>
<p>Ahora por la definición 3.3 y lo anterior tenemos que los residuales se encuentran de la forma:</p>
<p><span class="math display">\[\underline{e}=\underline{Y}-X \underline{\hat{\beta}}.\]</span></p>
<p><strong>Teorema 3.2</strong> (Mínimos Cuadrados).(MC) Si se minimiza la suma de cuadrados de la diferencia entre los valores observados y los estimados, la cual se expresa matricialmente de la siguiente forma:</p>
<p><span class="math display">\[\underline{e&#39;}\underline{e}.\]</span></p>
<p>Entonces se tiene como estimador de <span class="math inline">\(\underline{\beta}\)</span> a:</p>
<p><span class="math display">\[\underline{\hat{\beta}}=\left( X&#39;X\right)^{-1}X&#39;\underline{Y}.\]</span></p>
<p><strong>Demostración:</strong></p>
<p>Se sabe que los residuales están definidos como <span class="math inline">\(\underline{e}=\left( \underline{Y}-X \underline{\hat{\beta}}\right)\)</span> de esta manera, por hipótesis se tiene:</p>
<p><span class="math display">\[\underline{e&#39;}\underline{e}=\left( \underline{Y}-X \underline{\hat{\beta}}\right)&#39;\left( \underline{Y}-X \underline{\hat{\beta}}\right)\]</span>
<span class="math display">\[=\left(\underline{Y}&#39;- \underline{\hat{\beta}}&#39;X&#39;\right)\left( \underline{Y}-X \underline{\hat{\beta}}\right)\]</span>
<span class="math display">\[=\underline{Y}&#39;Y-\underline{Y}&#39;X\underline{\hat{\beta}}-\underline{\hat{\beta}}&#39;X&#39;\underline{Y}+\underline{\hat{\beta}}&#39;X&#39;X\underline{\hat{\beta}}\]</span>
<span class="math display">\[\underline{e&#39;}\underline{e}=\underline{Y}&#39;Y-2\underline{Y}&#39;X\underline{\hat{\beta}}+\underline{\hat{\beta}}&#39;X&#39;X\underline{\hat{\beta}}.\]</span>
Lo anterior se da ya que <span class="math inline">\(\underline{\hat{\beta}}&#39;X&#39;\underline{Y}\)</span> es una matriz de <span class="math inline">\(1\times 1\)</span>, es decir, un escalar, y que su transpuesta <span class="math inline">\((\underline{\hat{\beta}}&#39;X&#39;\underline{Y})&#39;=\underline{Y}&#39;X\underline{\hat{\beta}}\)</span> es el mismo escalar.</p>
<p>Derivando respecto a <span class="math inline">\(\underline{\hat{\beta}}\)</span> para hallar los posibles mínimos se divide la suma matricial de la siguiente forma:</p>
<p><span class="math display">\[\Delta \underline{\hat\beta}=\Delta_{1} \underline{\hat{\beta}}+\Delta_{2} \underline{\hat{\beta}}+\Delta_{3} \underline{\hat{\beta}}\]</span></p>
<p>Procederemos a derivar:</p>
<p><span class="math display">\[
\Delta\underline{\hat{\beta}}=\left\{
\begin{array}{ll}
\Delta_{1} \underline{\hat{\beta}} \ \ \ \ \ \left(\underline{Y}&#39;\underline{Y}\right)  \ \ \ \ \ \ \ \ =0 \\
\Delta_{2} \underline{\hat{\beta}} \ \ \ \ \left( -2\underline{Y}&#39;X\underline{\hat{\beta}}\right) \ \ = \left(-2\underline{Y}&#39;X\right)&#39;=-2X&#39;\underline{Y} \\
\Delta_{3} \underline{\hat{\beta}} \ \  \ \ \left( \underline{\hat{\beta}&#39;}X&#39;X\underline{\hat{\beta}}\right)  \ \ \ = 2X&#39;X\underline{\hat{\beta}}
\end{array}
\right.
\]</span></p>
<p>De esta forma se tiene que la derivada respecto a <span class="math inline">\(\underline{\beta}\)</span> es:</p>
<p><span class="math display">\[\Delta \underline{\beta}=-2X&#39;\underline{Y}+2X&#39;X\underline{\hat{\beta}}.\]</span>
Igualamos la derivada a 0, para hallar un punto crítico:</p>
<p><span class="math display">\[\Delta \underline{\hat{\beta}}=0\]</span>
<span class="math display">\[-2X&#39;\underline{Y}+2X&#39;X\underline{\hat{\beta}}=0\]</span>
<span class="math display">\[2X&#39;X\underline{\hat{\beta}}=2X&#39;\underline{Y}\]</span>
Esto se simplifica a:</p>
<p><span class="math display">\[X&#39;X\underline{\hat{\beta}}=X&#39;\underline{Y}\]</span>
Ahora multiplicamos ambos lados por la inversa de <span class="math inline">\(X&#39;X\)</span>, es decir, <span class="math inline">\((X&#39;X)^{-1}\)</span></p>
<p><span class="math display">\[\therefore \underline{\hat{\beta}}=\left(X&#39;X\right)^{-1}X&#39;\underline{Y}.\]</span>
Nótese que la inversa <span class="math inline">\(\left(X&#39;X\right)^{-1}\)</span> existe porque <span class="math inline">\(X\)</span> es de rango completo en las columnas, como se mencionó en la definición. Por lo que el producto matricial <span class="math inline">\(X&#39;X\)</span> es de rango completo (<span class="math inline">\(k+1\)</span>), es decir <span class="math inline">\(|X|\neq 0,\)</span> por lo que se garantiza la existencia de la inversa.</p>
<p>Realizando la segunda derivada, veremos si la función es cóncava o convexa para saber si es mínimo o máximo.</p>
<p><span class="math display">\[\Delta \Delta \underline{\hat{\beta}}=\left\{
\begin{array}{ll}
\Delta \Delta \underline{\hat{\beta}} \ \ \ \ -2X&#39; \underline{Y} \ \ =0 \\
\Delta \Delta \underline{\hat{\beta}} \ \ \ \ 2X&#39;X \underline{\hat{\beta}}  \ \ \ = \left(2X&#39;X\right)&#39; =2X&#39;X \\
\end{array}
\right.\]</span></p>
<p>Así <span class="math inline">\(\Delta \Delta \underline{\hat{\beta}}=2X&#39;X\)</span></p>
<p>De esta manera <span class="math inline">\(\Delta \Delta \underline{\hat{\beta}}&gt;0\)</span> ya que <span class="math inline">\(X&#39;X\)</span> es definida positiva , por consiguiente <span class="math inline">\((X&#39;X)^{-1}X&#39;\underline{Y}\)</span> es considerado un mínimo. Por lo tanto, <span class="math inline">\(\underline{\hat{\beta}}=\left(X&#39;X\right)^{-1}X&#39;\underline{Y}.\)</span> es el estimador de mínimos cuadrados del modelo de regresión múltiple.<span class="math inline">\(\blacksquare\)</span></p>
<p>Una vez encontrada una estimación a los parámetros desconocidos de <span class="math inline">\(\underline{\beta}\)</span>, será conveniente desarrollar algunas variantes en la forma en la que se denota a los residuales, para ello se define a la matriz <span class="math inline">\(H\)</span> como <span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;.\)</span> Cabe destacar que la matriz <span class="math inline">\(H\)</span> es conocida como <strong>“matriz sombrero”</strong>, que junto con la matriz <span class="math inline">\((I-H)\)</span> cumplen con ser matrices idempotentes, es decir, que al elevar las matrices a una potencia dada los valores contenidos en la matriz no se modifican; de igual forma ambas matrices cumplen con ser simétricas, denominadas así ya que al transponer las matrices los valores contenidos en ellas conservan su lugar.</p>
<p>Debemos considerar el siguiente resultado, el cual será importante al desarrollar el siguiente teorema 3.3 ya que demuestra que <span class="math inline">\((X&#39;X)^{-1}\)</span> es una matriz simétrica.</p>
<p><span class="math display">\[[(X&#39;X)^{-1}]&#39;=[(X&#39;X)&#39;]^{-1}\]</span>
<span class="math display">\[=(X&#39;(X&#39;)&#39;)^{-1}\]</span>
<span class="math display">\[\therefore [(X&#39;X)^{-1}]&#39;= (X&#39;X)^{-1}. \blacksquare\]</span>
Es decir, la inversa de <span class="math inline">\(X&#39;X\)</span> es simétrica, resultado importante en el siguiente teorema:</p>
<p><strong>Teorema 3.3</strong> Sea <span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;\)</span> e <span class="math inline">\((I-H)\)</span> entonces:</p>
<p><strong>a)</strong> Las matrices <span class="math inline">\(H\)</span> e <span class="math inline">\(I-H\)</span> son idempotentes.</p>
<p><strong>b)</strong> Las matrices <span class="math inline">\(H\)</span> e <span class="math inline">\(I-H\)</span> son simétricas.</p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong> Para demostrar la idempotencia de <span class="math inline">\(H\)</span> basta probar que <span class="math inline">\(H^2=H,\)</span> es decir, al elevar la matriz <span class="math inline">\(H\)</span> ésta no se alterará:</p>
<p><span class="math display">\[H^2=(X(X&#39;X)^{-1}X&#39;)(X(X&#39;X)^{-1}X&#39;)\]</span>
<span class="math display">\[=X(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}X&#39;.\]</span>
Transponiendo con la finalidad de simplificar el producto matricial y por el resultado mostrado anteriormente <span class="math inline">\([(X&#39;X)^{-1}]&#39;=(X&#39;X)^{-1}\)</span> se tiene:</p>
<p><span class="math display">\[=[(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}X&#39;]&#39;X&#39;\]</span>
<span class="math display">\[=[(X&#39;X)^{-1}X&#39;]&#39;X&#39;\]</span>
<span class="math display">\[=X(X&#39;X)^{-1}X&#39;\]</span></p>
<p><span class="math display">\[\therefore H^2=H.\]</span>
Por lo tanto <span class="math inline">\(H\)</span> es idempotente. <span class="math inline">\(\blacksquare\)</span></p>
<p>Para probar la idempotencia de <span class="math inline">\(I-H\)</span>, ésta será elevada al cuadrado.</p>
<p><span class="math display">\[(I-H)^2=(I-H)(I-H)\]</span>
<span class="math display">\[=I-IH-IH+H^2\]</span>
<span class="math display">\[=I-2H+H^2.\]</span></p>
<p>Por idempotencia de <span class="math inline">\(H\)</span>, <span class="math inline">\(H=H^2\)</span>. Por lo tanto:
<span class="math display">\[(I-H)=I-2H+H\]</span>
<span class="math display">\[\therefore (I-H)^2=I-H.\]</span></p>
<p><strong>b)</strong> Para demostrar la simetría de <span class="math inline">\(H\)</span>, se transpondrá la matriz <span class="math inline">\(H\)</span>. Además debemos recordar que <span class="math inline">\([(X&#39;X)^{-1}]&#39;=(X&#39;X)^{-1}\)</span> así:</p>
<p><span class="math display">\[H&#39;= (X(X&#39;X)^{-1}X&#39;)&#39;\]</span>
<span class="math display">\[=X(X&#39;X)^{-1}X&#39;\]</span>
<span class="math display">\[\therefore H&#39;= H.\]</span></p>
<p>Por lo tanto la matriz <span class="math inline">\(H\)</span> es simétrica.</p>
<p>Para la simetría de <span class="math inline">\(I-H\)</span> se transpone la matriz:</p>
<p><span class="math display">\[(I-H)&#39;=I&#39;-H&#39;.\]</span></p>
<p>Por simetría de H y de I</p>
<p><span class="math display">\[\therefore (I-H)^2=I-H\]</span></p>
<p>Por lo tanto <span class="math inline">\(I-H\)</span> es simétrica. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>Corolario 4</strong> Sea <span class="math inline">\(\underline{e}\)</span> la matriz de residuales, entonces éstos pueden ser expresados por la siguiente ecuación:</p>
<p><span class="math display">\[\underline{e}=(I-H)\underline{Y}\]</span>
donde <span class="math inline">\(I\)</span> es la matriz identidad, y <span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;.\)</span></p>
<p><strong>Demostración:</strong></p>
<p>Se sabe que los valores estimados son calculados de la siguiente manera:</p>
<p><span class="math display">\[\underline{\hat{Y}}=X\underline{\hat{\beta}}\]</span>
<span class="math display">\[\underline{\hat{Y}}=X(X&#39;X)^{-1}X&#39;\underline{Y}\]</span>
<span class="math display">\[\underline{\hat{Y}}=H\underline{Y}.\]</span>
donde <span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;.\)</span> De esta manera calculando la matriz de residuales se tiene:</p>
<p><span class="math display">\[\underline{e}=\underline{Y}-\underline{\hat{Y}}\]</span>
<span class="math display">\[\underline{e}=\underline{Y}-X\underline{\hat{\beta}}\]</span>
<span class="math display">\[\underline{e}=\underline{Y}-H\underline{Y}\]</span>
<span class="math display">\[\underline{e}=(I-H)\underline{Y}.\blacksquare\]</span></p>
<p>Como se mencionó en regresión lineal simple, <span class="math inline">\(SC_{error}\)</span> mide la variación residual que queda sin explicar por la línea de regresión, en el modelo de regresión múltiple es denotada como <span class="math inline">\(SC_{error}=\underline{e}&#39;\underline{e},\)</span> la cual es equivalente a la suma de residuales al cuadrado.</p>
<p><strong>Corolario 5</strong> La suma de cuadrados del error, puede denotarse matricialmente como:</p>
<p><span class="math display">\[SC_{error}=\underline{Y}&#39;(I-H)\underline{Y}.\]</span>
donde:</p>
<ul>
<li><p><span class="math inline">\(&quot;\underline{Y}&quot;\)</span> son los valores observados de la variable respuesta.</p></li>
<li><p><span class="math inline">\(I\)</span> es la matriz identidad.</p></li>
<li><p><span class="math inline">\(H=X(X&#39;X)^{-1}X&#39;.\)</span></p></li>
</ul>
<p><strong>Demostración:</strong></p>
<p>Se sabe por hipótesis que:</p>
<p><span class="math inline">\(SC_{error}=\underline{e}&#39;\underline{e}\)</span></p>
<p>Por el <strong>corolario 4</strong>, se puede expresar a los residuales como <span class="math inline">\(\underline{e}=(I-H)\underline{Y},\)</span> sustituyendo:</p>
<p><span class="math display">\[SC_{error}=((I-H)\underline{Y})&#39;((I-H)\underline{Y})\]</span></p>
<p><span class="math display">\[=(\underline{Y}&#39;(I-H)&#39;)((I-H)\underline{Y})\]</span></p>
<p><span class="math display">\[=(\underline{Y}&#39;(I-H))((I-H)\underline{Y})\]</span></p>
<p><span class="math display">\[=\underline{Y}&#39;(I-H)(I-H)\underline{Y}\]</span></p>
<p><span class="math display">\[=[(I-H)&#39;(I-H)&#39;\underline{Y}]\underline{Y}\]</span></p>
<p><span class="math display">\[=[(I-H)^2\underline{Y}]&#39;\underline{Y}\]</span></p>
<p><span class="math display">\[=\underline{Y}&#39;(I-H)&#39;\underline{Y}\]</span></p>
<p><span class="math display">\[\therefore SC_{error}=\underline{Y}&#39;(I-H)&#39;\underline{Y}.\]</span></p>
<p>Con los resultados, se procede a examinar las propiedades de los estimadores obtenidos por el método de mínimos cuadrados.
Éstas propiedades son agrupadas y enunciadas en el <strong>Teorema de Gauss-Markov</strong></p>
<p><strong>Teorema 3.4</strong> (Teorema de Gauss-Markov).</p>
<p>En el modelo de <strong>regresión lineal múltiple</strong> <span class="math inline">\(\underline{Y}=X \underline{\beta}+ \underline{\epsilon},\)</span> bajo la hipótesis:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{E}[\underline{\epsilon}]=0\)</span> y <span class="math inline">\(Var(\underline{\epsilon})=\sigma^2I_{n}.\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{E}[\underline{Y}]=X \underline{\beta}\)</span> y <span class="math inline">\(Var(\underline{Y})=\sigma^2I_{n}.\)</span></p></li>
<li><p>X de rango completo en las columnas.</p></li>
</ul>
<p>El estimador de mínimos cuadrados de <span class="math inline">\(\underline{\beta}\)</span>, es el <strong>MELI</strong> (<strong>BLUE</strong> por su abreviación en inglés), el mejor estimador lineal insesgado. Es decir, <span class="math inline">\(\underline{\hat{\beta}}\)</span> es insesgado y además, si <span class="math inline">\(\underline{\tilde{\beta}}\)</span> es otro estimador insesgado, entonces <span class="math inline">\(Var(\underline{\tilde{\beta}})\geq Var(\underline{\hat{\beta}})\)</span>, es decir, <span class="math inline">\(\underline{\hat{\beta}}\)</span> es de mínima varianza.</p>
<p><strong>Demostración:</strong></p>
<p>Para demostrar que el estimador <span class="math inline">\(\underline{\hat{\beta}}\)</span> es insesgado, es necesario probar que el estimador cumple que <span class="math inline">\(\mathbf{E}[\underline{\hat{\beta}}]=\underline{\beta}\)</span>, de ésta forma:</p>
<p><span class="math display">\[\mathbf{E}[\underline{\hat{\beta}}]=\mathbf{E}[(X&#39;X)^{-1}X&#39;\underline{Y}]\]</span>
Ya que <span class="math inline">\(X\)</span> son constantes</p>
<p><span class="math display">\[=(X&#39;X)^{-1}X&#39;\mathbf{E}[\underline{Y}]\]</span>
Ya que <span class="math inline">\(\mathbf{E}[\underline{Y}]=X\underline{\beta}\)</span></p>
<p><span class="math display">\[=(X&#39;X)^{-1}X&#39;X\beta\]</span>
<span class="math display">\[=I\beta\]</span></p>
<p><span class="math display">\[\therefore \mathbf{E}[\underline{\hat{\beta}}]=\underline{\beta}.\]</span>
Por lo tanto <span class="math inline">\(\underline{\hat{\beta}}\)</span> es un estimador insesgado para <span class="math inline">\(\underline{\beta}\)</span>.<span class="math inline">\(\blacksquare\)</span></p>
<p>Para conocer la varianza del estimador <span class="math inline">\(\underline{\hat{\beta}}\)</span> se sabe que:</p>
<p><span class="math display">\[Var(\underline{\hat{\beta}})=Var\left( (X&#39;X)^{-1}X&#39;\underline{Y}\right)\]</span>
<span class="math display">\[=(X&#39;X)^{-1}X&#39;Var(\underline{Y})[(X&#39;X)^{-1}X&#39;]&#39;\]</span>
Ya que la <span class="math inline">\(Var(\underline{Y})=\sigma^2I_{n}\)</span></p>
<p><span class="math display">\[=(X&#39;X)^{-1}X&#39;[(X&#39;X)^{-1}X&#39;]&#39;\sigma^2\]</span>
<span class="math display">\[=\sigma^2(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}\]</span>
<span class="math display">\[=\sigma^2I(X&#39;X)^{-1}\]</span>
<span class="math display">\[\therefore Var(\underline{\hat{\beta}})=\sigma^2(X&#39;X)^{-1}\]</span>
Para comprobar que el estimador <span class="math inline">\(\underline{\hat{\beta}}\)</span> es el estimador insesgado de mínima varianza, se propone a un estimador <span class="math inline">\(\underline{\tilde{\beta}}\)</span> el cual cumple con ser lineal e insesgado. Para ello sea <span class="math inline">\(\underline{\tilde{\beta}}\)</span> un estimador linealmente insesgado para <span class="math inline">\(\underline{\beta}\)</span>. Es decir, existe una matriz de <span class="math inline">\(A_{(k+1)\times n}\)</span> tal que <span class="math inline">\(\underline{\tilde{\beta}}=A \underline{Y}.\)</span>
De esta forma:</p>
<p><span class="math display">\[\mathbf{E}\left[\underline{\tilde{\beta}}\right]=\mathbf{E}\left[ A\underline{Y} \right]\]</span>
<span class="math display">\[=A \mathbf{E}[\underline{Y}]\]</span>
Ya que <span class="math inline">\(\mathbf{E}[\underline{Y}]=X\underline{\beta}\)</span></p>
<p><span class="math display">\[=AX\underline{\beta}\]</span>
<span class="math display">\[\mathbf{E}\left[\underline{\tilde{\beta}}\right]=AX\underline{\beta}\]</span></p>
<p>Para que sea un estimador insesgado, entonces <span class="math inline">\(AX\)</span> tiene que cumplir: <span class="math inline">\(AX=I\)</span>, así:</p>
<p><span class="math display">\[\mathbf{E}\left[\underline{\tilde{\beta}}\right]=I\underline{\beta}\]</span></p>
<p><span class="math display">\[\therefore \mathbf{E}\left[\underline{\tilde{\beta}}\right]=\underline{\beta}.\]</span></p>
<p>Para conocer la varianza de <span class="math inline">\(\underline{\tilde{\beta}}\)</span> se tiene:</p>
<p><span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)= Var(A\underline{Y})\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=A Var(\underline{Y})A&#39;\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2 AA&#39;.\]</span>
Sea <span class="math inline">\(C\)</span> una matriz de dimensión <span class="math inline">\((k+1) \times n\)</span> tal que <span class="math inline">\(C=A-(X&#39;X)^{-1}X&#39;\)</span>. Observe que <span class="math inline">\(CX=0\)</span> ya que <span class="math inline">\(CX=AX-(X&#39;X)^{-1}X&#39;X=I-I=0.\)</span>
De esta forma se tiene la siguiente igualdad:</p>
<p><span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2((X&#39;X)^{-1}X&#39;+C)((X&#39;X)^{-1}X&#39;+C)&#39;\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2((X&#39;X)^{-1}X&#39;+C)\left[ ((X&#39;X)^{-1}X&#39;)&#39;+C&#39;\right]\]</span></p>
<p><span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2((X&#39;X)^{-1}X&#39;+C)[X(X&#39;X)^{-1}+C&#39;]\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2[(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}+(X&#39;X)^{-1}X&#39;C&#39;+CX(X&#39;X)^{-1}+CC&#39;]\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2\left[(X&#39;X)^{-1}X&#39;X(X&#39;X)^{-1}+[CX(X&#39;X)^{-1}]&#39;+CX(X&#39;X)^{-1}+CC&#39;\right]\]</span>
Debido a que <span class="math inline">\(CX=0\)</span></p>
<p><span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2\left[ I(X&#39;X)^{-1}+0+0+CC&#39;\right]\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2[(X&#39;X)^{-1}+CC&#39;]\]</span>
<span class="math display">\[Var\left(\underline{\tilde{\beta}}\right)=\sigma^2(X&#39;X)^{-1}+\sigma^2CC&#39;.\]</span></p>
<p><span class="math display">\[\therefore Var\left(\underline{\tilde{\beta}}\right)=Var\left(\underline{\hat{\beta}}\right)+\sigma^2CC&#39;\]</span></p>
<p>Además se observa que <span class="math inline">\(CC&#39;\)</span>, es una matriz semidefinida positiva ya que los valores propios de <span class="math inline">\(CC&#39;\)</span> son reales y no negativos, además debido al supuesto de que <span class="math inline">\(X\)</span> es de rango completo para las columnas se cumple que <span class="math inline">\(rango(CC&#39;)=rango(X)=k+1,\)</span> esto es importante, ya que si no se cumple se tendría una solución no trivial, por lo que <span class="math inline">\(0\)</span> podría ser una solución para un egeinvalor por lo que no sería semidefinido positivo. Como <span class="math inline">\(CC&#39;\geq0\)</span>, se observa que:</p>
<p><span class="math display">\[Var\left(\underline{\tilde{\beta}}\right) \geq Var\left(\underline{\hat{\beta}}\right).\]</span>
Por lo que la varianza del estimador propuesto es mayor al obtenido por mínimos cuadrados. Por lo tanto, el estimador de <span class="math inline">\(MC\)</span> de <span class="math inline">\(\underline{\beta}\)</span> es el mejor estimador linealmente insesgado y de mínima varianza.<span class="math inline">\(\blacksquare\)</span></p>
<p>Las anteriores propiedades de los estimadores son importantes ya que garantizan que los valores estimados <span class="math inline">\(\underline{\hat{Y}}\)</span>, asignan valores que efectivamente recaen en el hiperplano propuesto en el modelo de regresión lineal múltiple.</p>
<p><strong>Teorema 3.5</strong> Sea <span class="math inline">\(\underline{\hat{Y}}\)</span>, los valores estimados de <span class="math inline">\(Y\)</span>, de forma que <span class="math inline">\(\underline{\hat{Y}}=X\underline{\hat{\beta}}\)</span>, entonces se cumple:</p>
<p><strong>a)</strong> <span class="math inline">\(\mathbf{E}[\underline{\hat{Y}}]=X\underline{\beta}.\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(Var(\underline{\hat{Y}})=\sigma^2H.\)</span></p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong> Para demostrar la esperanza de los valores estimados, se observa que:</p>
<p><span class="math display">\[\mathbf{E}[\underline{\hat{Y}}]=\mathbf{E}[X\underline{\hat{\beta}}]\]</span>
<span class="math display">\[\mathbf{E}[\underline{\hat{Y}}]=X\mathbf{E}[\underline{\hat{\beta}}]\]</span></p>
<p><span class="math display">\[\therefore \mathbf{E}[\underline{\hat{Y}}]=X\underline{\beta}. \blacksquare\]</span></p>
<p><strong>b)</strong> Para la varianza se tiene:</p>
<p><span class="math display">\[Var(\underline{\hat{Y}})=Var(X\underline{\hat{\beta}})\]</span>
<span class="math display">\[Var(\underline{\hat{Y}})=XVar(\underline{\hat{\beta}})X&#39;\]</span>
<span class="math display">\[Var(\underline{\hat{Y}})=X\sigma^2(X&#39;X)^{-1}X&#39;\]</span></p>
<p><span class="math display">\[Var(\underline{\hat{Y}})=\sigma^2X(X&#39;X)^{-1}X&#39;\]</span></p>
<p><span class="math display">\[\therefore Var(\underline{\hat{Y}})=\sigma^2H.\blacksquare\]</span></p>
<p><strong>Teorema 3.6</strong> Sea <span class="math inline">\(\underline{e}\)</span> los residuales del modelo, de forma <span class="math inline">\(\underline{e}=\underline{Y}-\underline{\hat{Y}}\)</span>, entonces cumplen con:</p>
<p><strong>a)</strong> <span class="math inline">\(\mathbf{E}[\underline{e}]=0.\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(Var(\underline{e})=\sigma^2(I-H).\)</span></p>
<p><strong>Demostración:</strong></p>
<p><span class="math inline">\(**a)**\)</span> Para demostar la esperanza de los residuales, se observa que:</p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=\mathbf{E}[\underline{Y}-\underline{\hat{Y}}]\]</span>
Por el <strong>corolario 4</strong></p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=\mathbf{E}[(I-H)\underline{Y}]\]</span>
<span class="math display">\[\mathbf{E}[\underline{e}]=(I-H)\mathbf{E}[\underline{Y}]\]</span></p>
<p>Por el <strong>teorema 3.4</strong></p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=(I-H)X\beta\]</span></p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=X\underline{\beta}-HX\underline{\beta}\]</span>
<span class="math display">\[\mathbf{E}[\underline{e}]=X\underline{\beta}-X(X&#39;X)^{-1}X&#39;X\underline{\beta}\]</span>
<span class="math display">\[\mathbf{E}[\underline{e}]=X\underline{\beta}-\left[X&#39;X(X&#39;X)^{-1}X&#39;\right]&#39;\underline{\beta}\]</span></p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=X\underline{\beta}-[IX&#39;]&#39;\underline{\beta}\]</span></p>
<p><span class="math display">\[\mathbf{E}[\underline{e}]=X\underline{\beta}-X\underline{\beta}\]</span>
<span class="math display">\[\therefore \mathbf{E}[\underline{e}]=0. \blacksquare\]</span></p>
<p><span class="math inline">\(**b)**\)</span> Para la varianza se tiene:</p>
<p><span class="math display">\[Var(\underline{e})=Var\left( \underline{Y}-\underline{\hat{Y}}\right)\]</span></p>
<p>Por el <strong>corolario 4</strong></p>
<p><span class="math display">\[Var(\underline{e})=Var\left( (I-H)\underline{\hat{Y}}\right)\]</span>
<span class="math display">\[Var(\underline{e})=(I-H)Var(\underline{\hat{Y}})(I-H)&#39;\]</span>
Por el <strong>teorema 3.3</strong></p>
<p><span class="math display">\[Var(\underline{e})=(I-H)\sigma^2(I-H)\]</span>
Por idempotencia de <span class="math inline">\(I-H\)</span></p>
<p><span class="math display">\[Var(\underline{e})=\sigma^2(I-H)(I-H)\]</span></p>
<p><span class="math display">\[\therefore Var(\underline{e})=\sigma^2(I-H). \blacksquare\]</span></p>
</div>
<div id="estimación-por-máxima-verosimilitud" class="section level2" number="28.4">
<h2><span class="header-section-number">28.4</span> Estimación por máxima verosimilitud</h2>
<p>Se han usado varios supuestos para poder calcular a los estimadores por medio del método de mínimos cuadrados, sin embargo, para hacer uso de la estimación por máxima verosimilitud se supondrá que los errores se distribuyen como una normal multivariada <span class="math inline">\(\underline{\epsilon} \sim \mathbf{N}_{n}(O_{n},\sigma^2 I_{n})\)</span> por lo que el modelo <span class="math inline">\(\underline{Y}\)</span> tiene distribución normal, es decir, <span class="math inline">\(\underline{Y} \sim \mathbf{N}_n (X\underline{\beta},\sigma^2).\)</span></p>
<p>Tenemos:</p>
<p><strong>Definición 3.4</strong> Tomando el supuesto de normalidad conjunta para los errores se cumple que:</p>
<ul>
<li><p><span class="math inline">\(\epsilon_{i}\)</span> es independiente <span class="math inline">\(\forall i\)</span> tal que <span class="math inline">\(i \neq j.\)</span></p></li>
<li><p><span class="math inline">\(\underline{Y}\sim \mathbf{N}_{n}(X\underline{\beta},\sigma^2).\)</span></p></li>
<li><p>Cada <span class="math inline">\(y_{i}\)</span> es independiente pero no es idénticamente distribuida.</p></li>
</ul>
<p>De esta forma se podrá usar el método de máxima verosimilitud para estimar a los parámetros desconocidos a través de la función de verosimilitud. Al realizar la estimación por éste método se obtendrán resultados parecidos a los obtenidos por mínimos cuadrados.</p>
<p><strong>Teorema 3.7</strong> (Función de verosimilitud).</p>
<p>Sea <span class="math inline">\(\underline{\hat{\beta}}\)</span> y <span class="math inline">\(\hat{\sigma}^2\)</span>, los estimadores de <span class="math inline">\(\underline{\beta}\)</span> y <span class="math inline">\(\sigma^2\)</span> respectivamente; suponiendo normalidad en los errores <span class="math inline">\(\underline{\epsilon} \sim \mathbf{N}_{n}(0_{n},\sigma^2 I_{n})\)</span> y <span class="math inline">\(\underline{Y}\sim \mathbf{N}_{n}(X \underline{\beta},\sigma^2)\)</span> entonces la estimación de los parámetros <span class="math inline">\(\underline{\beta}\)</span> y <span class="math inline">\(\sigma^2\)</span> por el método de máxima verosimilitud están dados por:</p>
<p><strong>a)</strong> <span class="math inline">\(\underline{\hat{\beta}}=(X&#39;X)^{-1}X&#39;\underline{Y}\)</span>.</p>
<p><strong>b)</strong> <span class="math inline">\(\hat{\sigma}^2=\frac{1}{n}\left( \underline{Y}-X\underline{\hat{\beta}}\right)&#39;\left(\underline{Y}-X \underline{\hat{\beta}}\right).\)</span></p>
<p><strong>Demostración:</strong></p>
<p>Por hipótesis <span class="math inline">\(\underline{Y}\sim \mathbf{N}_{n}(X\underline{\beta},\sigma^2 I_{n})\)</span>, escribiendo la función de verosimilitud se tiene que:</p>
<p><span class="math display">\[L(\underline{\beta},\sigma^2 \mid \underline{Y},X)=\prod_{i=1}^{n}(2\pi\sigma^2)^{-1/2} exp \left[ - \frac{1}{2\sigma^2}(\underline{Y}-\mu)&#39;(\underline{Y}-\mu) \right]\]</span></p>
<p><span class="math display">\[L(\underline{\beta},\sigma^2 \mid \underline{Y},X)=(2\pi\sigma^2)^{\sum_{i=1}^{n}-1/2} exp \left[ - \frac{1}{2\sigma^2}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta}) \right]\]</span>
<span class="math display">\[L(\underline{\beta},\sigma^2 \mid \underline{Y},X)=(2\pi\sigma^2)^{-n/2} exp \left[ - \frac{1}{2\sigma^2}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta}) \right].\]</span></p>
<p>Aplicando logaritmo natural a la función de verosimilitud:</p>
<p><span class="math display">\[lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)= -\frac{n}{2}ln(2\pi\sigma^2)-\frac{1}{2\sigma^2}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})\]</span>
<span class="math display">\[lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)= -\frac{n}{2}[ln(2\pi)+ln(\sigma^2)]-\frac{1}{2\sigma^2}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})\]</span>
<span class="math display">\[lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)= -\frac{n}{2}ln(2\pi)-\frac{n}{2}ln(\sigma^2)-\frac{1}{2\sigma^2}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})\]</span></p>
<p><strong>a)</strong> Derivando respecto a <span class="math inline">\(\underline{\beta}\)</span> para obtener su estimador.</p>
<p><span class="math display">\[\frac{\partial}{\partial \underline{\beta}}lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)=-\frac{1}{2\sigma^2}2(X&#39;X\underline{\beta}-X&#39;\underline{Y}).\]</span>
<span class="math display">\[\frac{\partial}{\partial \underline{\beta}}lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)=-\frac{1}{\sigma^2}(X&#39;X\underline{\beta}-X&#39;\underline{Y}).\]</span></p>
<p>Igualando la derivada a 0, para encontrar el punto silla</p>
<p><span class="math display">\[\frac{\partial}{\partial \underline{\beta}}lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)=0\]</span></p>
<p><span class="math display">\[-\frac{1}{\sigma^2}(X&#39;X\underline{\beta}-X&#39;\underline{Y})=0\]</span></p>
<p><span class="math display">\[(X&#39;X\underline{\beta}-X&#39;\underline{Y})=0\]</span></p>
<p><span class="math display">\[X&#39;X\underline{\beta}=X&#39;\underline{Y}\]</span></p>
<p><span class="math display">\[\therefore \underline{\hat{\beta}}=(X&#39;X)^{-1}X&#39;\underline{Y}. \blacksquare\]</span></p>
<p>Ya que <span class="math inline">\(X\)</span> es de rango completo por columnas entonces existe <span class="math inline">\((X&#39;X)^{-1}.\)</span></p>
<p><strong>b)</strong> Derivando respecto a <span class="math inline">\(\sigma^2\)</span> para obtener su estimador:</p>
<p><span class="math display">\[\frac{\partial}{\partial\sigma^2}lnL(\underline{\beta},\sigma^2 \mid \underline{Y},X)=-\frac{n}{2\sigma^2}+\frac{1}{2\sigma^4}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta}).\]</span></p>
<p>Igualando la derivada parcial a 0 para hallar el punto crítico de un posible máximo.</p>
<p><span class="math display">\[\frac{\partial}{\partial\sigma^2}lnL(\underline{\beta}, \sigma^2 \mid \underline{Y},X)=0\]</span>
<span class="math display">\[-\frac{n}{2\sigma^2}+\frac{1}{2\sigma^4}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})=0\]</span>
<span class="math display">\[\frac{1}{2\sigma^4}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})=\frac{n}{2\sigma^2}\]</span>
<span class="math display">\[(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})=n\sigma^2\]</span>
<span class="math display">\[\therefore \hat{\sigma}^2=\frac{1}{n}\left( \underline{Y}-X\underline{\hat{\beta}}\right)&#39;\left(\underline{Y}-X \underline{\hat{\beta}}\right).\blacksquare\]</span></p>
<p>Por lo tanto los estimadores de máxima verosimilitud son:</p>
<p><span class="math display">\[
\begin{array}{c}
\underline{\hat{\beta}}=(X&#39;X)^{-1}X&#39;\underline{Y} \\
y \\
\hat{\sigma}^2=\frac{1}{n}\left( \underline{Y}-X\underline{\hat{\beta}}\right)&#39;\left(\underline{Y}-X \underline{\hat{\beta}}\right)
\blacksquare
\end{array}
\]</span></p>
<p>Se observa que el estimador de <span class="math inline">\(\underline{\beta}\)</span> obtenido por el método de mínimos cuadrados es similar al estimador por máxima verosimilitud, sin embargo, éste último aporta mayor información al proporcionar el estimador para la varianza del modelo <span class="math inline">\(\hat{\sigma}^2.\)</span></p>
<p>De igual forma el estimador <span class="math inline">\(\hat{\sigma}^2_{MV}\)</span> guarda cierta relación con la suma de cuadrados residuales ya que se tiene:</p>
<p><span class="math display">\[\hat{\sigma}^2_{MV}=\frac{1}{n}(\underline{Y}-X\underline{\beta})&#39;(\underline{Y}-X\underline{\beta})\]</span>
Por el <strong>corolario 4</strong></p>
<p><span class="math display">\[\hat{\sigma}^2_{MV}=\frac{1}{n}SC_{error}\]</span></p>
<p>Por el <strong>corolario 5</strong></p>
<p><span class="math display">\[\hat{\sigma}^2_{MV}=\frac{1}{n}\underline{e}&#39; \ \underline{e}\]</span>
<span class="math display">\[\hat{\sigma}^2_{MV}=\frac{1}{n}\underline{Y}&#39;(I-H)\underline{Y}.\]</span>
Cabe destacar, que el estimador de <span class="math inline">\(\underline{\beta}\)</span> por máxima verosimilitud hereda todas las propiedades que cumple el estimador de mínimos cuadrados del teorema 3.4, es decir, <span class="math inline">\(\underline{\hat{\beta}}\)</span> es insesgado y de mínima varianza, sin embargo, el método de máxima verosimilitud proporciona una estimación para <span class="math inline">\(\sigma^2\)</span> el cual cumple con tener sesgo <span class="math inline">\((\mathbf{E}[\sigma^2]\neq 0).\)</span></p>
<p><span class="math display">\[\mathbf{E}[\hat{\sigma}^2]=\mathbf{E}\left[\frac{1}{n}\sum_{i=1}^{n}(\underline{Y_{i}}-\underline{\hat{Y}})&#39;(\underline{Y_{i}}-\underline{\hat{Y}}) \right]\]</span></p>
<p><span class="math display">\[=\frac{1}{n}\sum_{i=1}^{n}\mathbf{E}\left[(\underline{Y_{i}}+X\underline{\beta}-X\underline{\beta}-X\underline{\hat{\beta}})&#39;(\underline{Y_{i}}+X\underline{\beta}-X\underline{\beta}-X\underline{\hat{\beta}}) \right]\]</span>
<span class="math display">\[=\frac{1}{n}\sum_{i=1}^{n}\left(\mathbf{E}[(\underline{Y_{i}}-X\underline{\beta})(\underline{Y_{i}}-X\underline{\beta})&#39;]-\mathbf{E}\left[(X\underline{\hat{\beta}}-X\underline{\beta})(X\underline{\hat{\beta}}-X\underline{\beta})&#39;\right] \right)\]</span>
<span class="math display">\[=\sigma^2-\frac{1}{n^2}\mathbf{E}\left[\frac{1}{n}\sum_{i=1}^{n}(\underline{Y_{i}}-\underline{\hat{Y}})(\underline{Y_{i}}-\underline{\hat{Y}})&#39;-\sum_{i=1}^{n}(\underline{Y_{i}}-\underline{\hat{Y}})(\underline{Y_{i}}-\underline{\hat{Y}})&#39;\right]\]</span></p>
<p><span class="math display">\[=\sigma^2-\frac{n^2-nk-n}{n}\sigma^2\]</span></p>
<p><span class="math display">\[\therefore \mathbf{E}[\hat{\sigma}^2]=\frac{n-k-1}{n}\sigma^2.\]</span></p>
<p>Por lo tanto el estimador <span class="math inline">\(\hat{\sigma}^2\)</span> no es insesgado.<span class="math inline">\(\blacksquare\)</span></p>
<p>El método de mínimos cuadrados no proporciona información acerca de la estimación de varianza del modelo <span class="math inline">\(\sigma^2\)</span>, es por ello que se propone al estimador:</p>
<p><span class="math display">\[\sigma^2_{MC}=\frac{SC_{error}}{n-k-1}.\]</span></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Tesisdelicenciatura2019Estadistica" class="csl-entry">
Omar, Rodríguez Torres. 2019. <em>Estad<span>í</span>stica No Param<span>é</span>trica y an<span>á</span>lisis de Regresi<span>ó</span>n. Una Introducci<span>ó</span>n Para Estudiantes de La Licenciatura de Actuar<span>í</span>a.</em> UNAM.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="validación-de-supuestos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervalos-de-confianza-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "github", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
