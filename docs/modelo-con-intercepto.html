<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 23 Modelo con intercepto | Modelos no paramétricos y de Regresión</title>
  <meta name="description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 23 Modelo con intercepto | Modelos no paramétricos y de Regresión" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/Dul-Reyes/MNPyR" />
  
  <meta property="og:description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  <meta name="github-repo" content="Dul-Reyes/MNPyR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 23 Modelo con intercepto | Modelos no paramétricos y de Regresión" />
  
  <meta name="twitter:description" content="Material para el curso Modelos no paramétricos y de regresión 2021-2 en la Facultad de Ciencias, Universidad Nacional Autónoma de México" />
  

<meta name="author" content="Sofía Villers Gómez" />
<meta name="author" content="Dulce María Reyes Varela" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introducción-5.html"/>
<link rel="next" href="modelo-sin-intercepto.html"/>
<script src="libs/header-attrs-2.7.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos no paramétricos y de Regresión</a></li>

<li class="divider"></li>
<li><a href="index.html#prefacio" id="toc-prefacio">Prefacio</a>
<ul>
<li><a href="index.html#objetivos" id="toc-objetivos">Objetivos</a></li>
<li><a href="index.html#licencia" id="toc-licencia">Licencia</a></li>
</ul></li>
<li><a href="introducción.html#introducción" id="toc-introducción">Introducción</a></li>
<li><a href="#part-un-primer-vistazo" id="toc-part-un-primer-vistazo">(PART) Un primer vistazo</a></li>
<li><a href="escalas-de-medición.html#escalas-de-medición" id="toc-escalas-de-medición"><span class="toc-section-number">1</span> Escalas de Medición</a>
<ul>
<li><a href="escalas-de-medición.html#variables-categóricas" id="toc-variables-categóricas"><span class="toc-section-number">1.1</span> Variables categóricas</a>
<ul>
<li><a href="escalas-de-medición.html#escala-nominal" id="toc-escala-nominal"><span class="toc-section-number">1.1.1</span> Escala nominal:</a></li>
<li><a href="escalas-de-medición.html#escala-ordinal" id="toc-escala-ordinal"><span class="toc-section-number">1.1.2</span> Escala ordinal:</a></li>
</ul></li>
<li><a href="escalas-de-medición.html#variables-cuantitativas" id="toc-variables-cuantitativas"><span class="toc-section-number">1.2</span> Variables cuantitativas</a>
<ul>
<li><a href="escalas-de-medición.html#escala-de-intervalo" id="toc-escala-de-intervalo"><span class="toc-section-number">1.2.1</span> Escala de intervalo:</a></li>
<li><a href="escalas-de-medición.html#escala-de-razón" id="toc-escala-de-razón"><span class="toc-section-number">1.2.2</span> Escala de razón:</a></li>
</ul></li>
</ul></li>
<li><a href="#part-pruebas-binomiales" id="toc-part-pruebas-binomiales">(PART) Pruebas Binomiales</a></li>
<li><a href="introducción-1.html#introducción-1" id="toc-introducción-1">Introducción</a></li>
<li><a href="prueba-de-proporciones.html#prueba-de-proporciones" id="toc-prueba-de-proporciones"><span class="toc-section-number">2</span> Prueba de Proporciones</a>
<ul>
<li><a href="prueba-de-proporciones.html#datos" id="toc-datos"><span class="toc-section-number">2.1</span> Datos</a></li>
<li><a href="prueba-de-proporciones.html#supuestos" id="toc-supuestos"><span class="toc-section-number">2.2</span> Supuestos</a></li>
<li><a href="prueba-de-proporciones.html#estadístico-de-prueba" id="toc-estadístico-de-prueba"><span class="toc-section-number">2.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-proporciones.html#hipótesis" id="toc-hipótesis"><span class="toc-section-number">2.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-proporciones.html#caso-a-prueba-de-dos-colas" id="toc-caso-a-prueba-de-dos-colas">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-proporciones.html#caso-b-prueba-de-cola-inferior" id="toc-caso-b-prueba-de-cola-inferior">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-proporciones.html#caso-c-prueba-de-cola-superior" id="toc-caso-c-prueba-de-cola-superior">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-proporciones.html#intervalos-de-confianza" id="toc-intervalos-de-confianza"><span class="toc-section-number">2.5</span> Intervalos de Confianza</a></li>
<li><a href="prueba-de-proporciones.html#ejemplo" id="toc-ejemplo"><span class="toc-section-number">2.6</span> Ejemplo</a></li>
<li><a href="prueba-de-proporciones.html#ejemplo-en-r-studio" id="toc-ejemplo-en-r-studio"><span class="toc-section-number">2.7</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-proporciones.html#ejercicios" id="toc-ejercicios"><span class="toc-section-number">2.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-cuantiles.html#prueba-de-cuantiles" id="toc-prueba-de-cuantiles"><span class="toc-section-number">3</span> Prueba de Cuantiles</a>
<ul>
<li><a href="prueba-de-cuantiles.html#datos-1" id="toc-datos-1"><span class="toc-section-number">3.1</span> Datos</a></li>
<li><a href="prueba-de-cuantiles.html#supuestos-1" id="toc-supuestos-1"><span class="toc-section-number">3.2</span> Supuestos</a></li>
<li><a href="prueba-de-cuantiles.html#estadístico-de-prueba-1" id="toc-estadístico-de-prueba-1"><span class="toc-section-number">3.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-cuantiles.html#hipótesis-1" id="toc-hipótesis-1"><span class="toc-section-number">3.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-cuantiles.html#caso-a-prueba-de-dos-colas-1" id="toc-caso-a-prueba-de-dos-colas-1">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-cuantiles.html#caso-b-prueba-de-cola-inferior-1" id="toc-caso-b-prueba-de-cola-inferior-1">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-cuantiles.html#caso-c-prueba-de-cola-supeior" id="toc-caso-c-prueba-de-cola-supeior">Caso C (Prueba de cola supeior)</a></li>
</ul></li>
<li><a href="prueba-de-cuantiles.html#ejemplo-1" id="toc-ejemplo-1"><span class="toc-section-number">3.5</span> Ejemplo</a></li>
<li><a href="prueba-de-cuantiles.html#ejemplo-en-r-studio-1" id="toc-ejemplo-en-r-studio-1"><span class="toc-section-number">3.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-cuantiles.html#ejercicios-1" id="toc-ejercicios-1"><span class="toc-section-number">3.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-signos.html#prueba-de-signos" id="toc-prueba-de-signos"><span class="toc-section-number">4</span> Prueba de Signos</a>
<ul>
<li><a href="prueba-de-signos.html#datos-2" id="toc-datos-2"><span class="toc-section-number">4.1</span> Datos</a></li>
<li><a href="prueba-de-signos.html#supuestos-2" id="toc-supuestos-2"><span class="toc-section-number">4.2</span> Supuestos</a></li>
<li><a href="prueba-de-signos.html#estadístico-de-prueba-2" id="toc-estadístico-de-prueba-2"><span class="toc-section-number">4.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-signos.html#hipótesis-2" id="toc-hipótesis-2"><span class="toc-section-number">4.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-signos.html#caso-a-prueba-de-dos-colas-2" id="toc-caso-a-prueba-de-dos-colas-2">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-signos.html#caso-b-prueba-de-cola-inferior-2" id="toc-caso-b-prueba-de-cola-inferior-2">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-signos.html#caso-c-prueba-de-cola-superior-1" id="toc-caso-c-prueba-de-cola-superior-1">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-signos.html#ejemplo-2" id="toc-ejemplo-2"><span class="toc-section-number">4.5</span> Ejemplo</a></li>
<li><a href="prueba-de-signos.html#ejemplo-en-r-studio-2" id="toc-ejemplo-en-r-studio-2"><span class="toc-section-number">4.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-signos.html#ejercicios-2" id="toc-ejercicios-2"><span class="toc-section-number">4.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-mc-nemar.html#prueba-mc-nemar" id="toc-prueba-mc-nemar"><span class="toc-section-number">5</span> Prueba Mc Nemar</a>
<ul>
<li><a href="prueba-mc-nemar.html#datos-3" id="toc-datos-3"><span class="toc-section-number">5.1</span> Datos</a></li>
<li><a href="prueba-mc-nemar.html#supuestos-3" id="toc-supuestos-3"><span class="toc-section-number">5.2</span> Supuestos</a></li>
<li><a href="prueba-mc-nemar.html#estadístico-de-prueba-3" id="toc-estadístico-de-prueba-3"><span class="toc-section-number">5.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-mc-nemar.html#hipótesis-3" id="toc-hipótesis-3"><span class="toc-section-number">5.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-mc-nemar.html#caso-a-prueba-de-dos-colas-3" id="toc-caso-a-prueba-de-dos-colas-3">Caso A (Prueba de dos colas)</a></li>
</ul></li>
<li><a href="prueba-mc-nemar.html#ejemplo-3" id="toc-ejemplo-3"><span class="toc-section-number">5.5</span> Ejemplo</a></li>
<li><a href="prueba-mc-nemar.html#ejemplo-en-r-studio-3" id="toc-ejemplo-en-r-studio-3"><span class="toc-section-number">5.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-mc-nemar.html#ejercicios-3" id="toc-ejercicios-3"><span class="toc-section-number">5.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-cox-stuart.html#prueba-de-cox-stuart" id="toc-prueba-de-cox-stuart"><span class="toc-section-number">6</span> Prueba de Cox Stuart</a>
<ul>
<li><a href="prueba-de-cox-stuart.html#datos-4" id="toc-datos-4"><span class="toc-section-number">6.1</span> Datos</a></li>
<li><a href="prueba-de-cox-stuart.html#supuestos-4" id="toc-supuestos-4"><span class="toc-section-number">6.2</span> Supuestos</a></li>
<li><a href="prueba-de-cox-stuart.html#estadístico-de-prueba-4" id="toc-estadístico-de-prueba-4"><span class="toc-section-number">6.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-cox-stuart.html#hipótesis-4" id="toc-hipótesis-4"><span class="toc-section-number">6.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-cox-stuart.html#caso-a-prueba-de-dos-colas-4" id="toc-caso-a-prueba-de-dos-colas-4">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-de-cox-stuart.html#caso-b-prueba-de-cola-inferior-3" id="toc-caso-b-prueba-de-cola-inferior-3">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-de-cox-stuart.html#caso-c-prueba-de-cola-superior-2" id="toc-caso-c-prueba-de-cola-superior-2">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-de-cox-stuart.html#ejemplo-4" id="toc-ejemplo-4"><span class="toc-section-number">6.5</span> Ejemplo</a></li>
<li><a href="prueba-de-cox-stuart.html#ejemplo-en-r-studio-4" id="toc-ejemplo-en-r-studio-4"><span class="toc-section-number">6.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-cox-stuart.html#ejercicios-4" id="toc-ejercicios-4"><span class="toc-section-number">6.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="#part-prueba-de-rango" id="toc-part-prueba-de-rango">(PART) Prueba de Rango</a></li>
<li><a href="introducción-2.html#introducción-2" id="toc-introducción-2">Introducción</a></li>
<li><a href="prueba-u-mann-y-witney.html#prueba-u-mann-y-witney" id="toc-prueba-u-mann-y-witney"><span class="toc-section-number">7</span> Prueba U-Mann y Witney</a>
<ul>
<li><a href="prueba-u-mann-y-witney.html#datos-5" id="toc-datos-5"><span class="toc-section-number">7.1</span> Datos</a></li>
<li><a href="prueba-u-mann-y-witney.html#supuestos-5" id="toc-supuestos-5"><span class="toc-section-number">7.2</span> Supuestos</a></li>
<li><a href="prueba-u-mann-y-witney.html#estadístico-de-prueba-5" id="toc-estadístico-de-prueba-5"><span class="toc-section-number">7.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-u-mann-y-witney.html#hipótesis-5" id="toc-hipótesis-5"><span class="toc-section-number">7.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-u-mann-y-witney.html#caso-a-prueba-de-dos-colas-5" id="toc-caso-a-prueba-de-dos-colas-5">Caso A (Prueba de dos colas)</a></li>
<li><a href="prueba-u-mann-y-witney.html#caso-b-prueba-de-cola-inferior-4" id="toc-caso-b-prueba-de-cola-inferior-4">Caso B (Prueba de cola inferior)</a></li>
<li><a href="prueba-u-mann-y-witney.html#caso-c-prueba-de-cola-superior-3" id="toc-caso-c-prueba-de-cola-superior-3">Caso C (Prueba de cola superior)</a></li>
</ul></li>
<li><a href="prueba-u-mann-y-witney.html#ejemplo-5" id="toc-ejemplo-5"><span class="toc-section-number">7.5</span> Ejemplo</a></li>
<li><a href="prueba-u-mann-y-witney.html#ejemplo-en-r-studio-5" id="toc-ejemplo-en-r-studio-5"><span class="toc-section-number">7.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#intervalo-de-confianza-para-la-diferencia-entre-dos-medias" id="toc-intervalo-de-confianza-para-la-diferencia-entre-dos-medias"><span class="toc-section-number">8</span> Intervalo de confianza para la diferencia entre dos medias</a>
<ul>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#datos-6" id="toc-datos-6"><span class="toc-section-number">8.1</span> Datos</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#supuestos-6" id="toc-supuestos-6"><span class="toc-section-number">8.2</span> Supuestos</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#método" id="toc-método"><span class="toc-section-number">8.3</span> Método</a></li>
<li><a href="intervalo-de-confianza-para-la-diferencia-entre-dos-medias.html#ejemplo-6" id="toc-ejemplo-6"><span class="toc-section-number">8.4</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-de-kruskal-wallis.html#prueba-de-kruskal-wallis" id="toc-prueba-de-kruskal-wallis"><span class="toc-section-number">9</span> Prueba de Kruskal-Wallis</a>
<ul>
<li><a href="prueba-de-kruskal-wallis.html#datos-7" id="toc-datos-7"><span class="toc-section-number">9.1</span> Datos</a></li>
<li><a href="prueba-de-kruskal-wallis.html#supuestos-7" id="toc-supuestos-7"><span class="toc-section-number">9.2</span> Supuestos</a></li>
<li><a href="prueba-de-kruskal-wallis.html#hipótesis-6" id="toc-hipótesis-6"><span class="toc-section-number">9.3</span> Hipótesis</a></li>
<li><a href="prueba-de-kruskal-wallis.html#estadístico-de-prueba-6" id="toc-estadístico-de-prueba-6"><span class="toc-section-number">9.4</span> Estadístico de prueba</a></li>
<li><a href="prueba-de-kruskal-wallis.html#regla-de-decisión-16" id="toc-regla-de-decisión-16"><span class="toc-section-number">9.5</span> Regla de decisión</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejemplo-7" id="toc-ejemplo-7"><span class="toc-section-number">9.6</span> Ejemplo</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejemplo-en-r-studio-6" id="toc-ejemplo-en-r-studio-6"><span class="toc-section-number">9.7</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-kruskal-wallis.html#ejercicios-5" id="toc-ejercicios-5"><span class="toc-section-number">9.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#prueba-de-igualdad-de-varianzas" id="toc-prueba-de-igualdad-de-varianzas"><span class="toc-section-number">10</span> Prueba de Igualdad de Varianzas</a>
<ul>
<li><a href="prueba-de-igualdad-de-varianzas.html#prueba-de-igualdad-de-varianzas-para-2-poblaciones" id="toc-prueba-de-igualdad-de-varianzas-para-2-poblaciones">Prueba de Igualdad de Varianzas para 2 poblaciones</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#datos-8" id="toc-datos-8"><span class="toc-section-number">10.1</span> Datos</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#supuestos-8" id="toc-supuestos-8"><span class="toc-section-number">10.2</span> Supuestos</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#estadístico-de-prueba-7" id="toc-estadístico-de-prueba-7"><span class="toc-section-number">10.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#hipótesis-7" id="toc-hipótesis-7"><span class="toc-section-number">10.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-a-prueba-de-dos-colas-6" id="toc-caso-a-prueba-de-dos-colas-6">Caso A Prueba de dos colas</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-b-prueba-de-cola-inferior-5" id="toc-caso-b-prueba-de-cola-inferior-5">Caso B Prueba de cola inferior</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#caso-c-prueba-de-cola-superior-4" id="toc-caso-c-prueba-de-cola-superior-4">Caso C Prueba de cola superior</a></li>
</ul></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejemplo-8" id="toc-ejemplo-8"><span class="toc-section-number">10.5</span> Ejemplo</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejemplo-en-r-studio-7" id="toc-ejemplo-en-r-studio-7"><span class="toc-section-number">10.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-igualdad-de-varianzas.html#ejercicios-6" id="toc-ejercicios-6"><span class="toc-section-number">10.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-para-más-de-dos-muestras.html#prueba-para-más-de-dos-muestras" id="toc-prueba-para-más-de-dos-muestras"><span class="toc-section-number">11</span> Prueba para más de dos Muestras</a>
<ul>
<li><a href="prueba-para-más-de-dos-muestras.html#datos-9" id="toc-datos-9"><span class="toc-section-number">11.1</span> Datos</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#hipótesis-8" id="toc-hipótesis-8"><span class="toc-section-number">11.2</span> Hipótesis</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#estadístico-de-prueba-8" id="toc-estadístico-de-prueba-8"><span class="toc-section-number">11.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#regla-de-decisión-20" id="toc-regla-de-decisión-20"><span class="toc-section-number">11.4</span> Regla de decisión</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#comparación-múltiple" id="toc-comparación-múltiple"><span class="toc-section-number">11.5</span> Comparación múltiple</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#ejemplo-9" id="toc-ejemplo-9"><span class="toc-section-number">11.6</span> Ejemplo</a></li>
<li><a href="prueba-para-más-de-dos-muestras.html#ejemplo-en-r-studio-8" id="toc-ejemplo-en-r-studio-8"><span class="toc-section-number">11.7</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="#part-tablas-de-contingencia" id="toc-part-tablas-de-contingencia">(PART) Tablas de Contingencia</a></li>
<li><a href="introducción-3.html#introducción-3" id="toc-introducción-3">Introducción</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#tablas-de-contingencia-de-2x2" id="toc-tablas-de-contingencia-de-2x2"><span class="toc-section-number">12</span> Tablas de Contingencia de 2x2</a>
<ul>
<li><a href="tablas-de-contingencia-de-2x2.html#datos-10" id="toc-datos-10"><span class="toc-section-number">12.1</span> Datos</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#supuestos-9" id="toc-supuestos-9"><span class="toc-section-number">12.2</span> Supuestos</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#estadístico-de-prueba-9" id="toc-estadístico-de-prueba-9"><span class="toc-section-number">12.3</span> Estadístico de Prueba</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#hipótesis-9" id="toc-hipótesis-9"><span class="toc-section-number">12.4</span> Hipótesis</a>
<ul>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-a-prueba-de-dos-colas-7" id="toc-caso-a-prueba-de-dos-colas-7">Caso A Prueba de dos colas</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-b-prueba-de-cola-inferior-6" id="toc-caso-b-prueba-de-cola-inferior-6">Caso B Prueba de cola inferior</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#caso-c-prueba-de-cola-superior-5" id="toc-caso-c-prueba-de-cola-superior-5">Caso C Prueba de cola superior</a></li>
</ul></li>
<li><a href="tablas-de-contingencia-de-2x2.html#ejemplo-10" id="toc-ejemplo-10"><span class="toc-section-number">12.5</span> Ejemplo</a></li>
<li><a href="tablas-de-contingencia-de-2x2.html#ejemplo-en-r-studio-9" id="toc-ejemplo-en-r-studio-9"><span class="toc-section-number">12.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="prueba-de-independencia.html#prueba-de-independencia" id="toc-prueba-de-independencia"><span class="toc-section-number">13</span> Prueba de Independencia</a>
<ul>
<li><a href="prueba-de-independencia.html#datos-11" id="toc-datos-11"><span class="toc-section-number">13.1</span> Datos</a></li>
<li><a href="prueba-de-independencia.html#supuestos-10" id="toc-supuestos-10"><span class="toc-section-number">13.2</span> Supuestos</a></li>
<li><a href="prueba-de-independencia.html#estadístico-de-prueba-10" id="toc-estadístico-de-prueba-10"><span class="toc-section-number">13.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-independencia.html#hipótesis-10" id="toc-hipótesis-10"><span class="toc-section-number">13.4</span> Hipótesis</a></li>
<li><a href="prueba-de-independencia.html#ejercicio" id="toc-ejercicio"><span class="toc-section-number">13.5</span> Ejercicio</a></li>
<li><a href="prueba-de-independencia.html#ejemplo-en-r-studio-10" id="toc-ejemplo-en-r-studio-10"><span class="toc-section-number">13.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-independencia.html#ejercicios-7" id="toc-ejercicios-7"><span class="toc-section-number">13.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#tablas-de-contingecia-de-r-times-c" id="toc-tablas-de-contingecia-de-r-times-c"><span class="toc-section-number">14</span> Tablas de Contingecia de <span class="math inline">\(r \times c\)</span></a>
<ul>
<li><a href="tablas-de-contingecia-de-r-times-c.html#prueba-de-chi2-para-tablas-de-contingencia-proporciones" id="toc-prueba-de-chi2-para-tablas-de-contingencia-proporciones">Prueba de <span class="math inline">\(\chi^2\)</span> para Tablas de Contingencia (Proporciones)</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#datos-12" id="toc-datos-12"><span class="toc-section-number">14.1</span> Datos</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#supuestos-11" id="toc-supuestos-11"><span class="toc-section-number">14.2</span> Supuestos</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#estadístico-de-prueba-11" id="toc-estadístico-de-prueba-11"><span class="toc-section-number">14.3</span> Estadístico de Prueba</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#hipótesis-11" id="toc-hipótesis-11"><span class="toc-section-number">14.4</span> Hipótesis</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejercicio-1" id="toc-ejercicio-1"><span class="toc-section-number">14.5</span> Ejercicio</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejemplo-en-r-studio-11" id="toc-ejemplo-en-r-studio-11"><span class="toc-section-number">14.6</span> Ejemplo en R-Studio</a></li>
<li><a href="tablas-de-contingecia-de-r-times-c.html#ejercicios-8" id="toc-ejercicios-8"><span class="toc-section-number">14.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-de-la-mediana.html#prueba-de-la-mediana" id="toc-prueba-de-la-mediana"><span class="toc-section-number">15</span> Prueba de la Mediana</a>
<ul>
<li><a href="prueba-de-la-mediana.html#datos-13" id="toc-datos-13"><span class="toc-section-number">15.1</span> Datos</a></li>
<li><a href="prueba-de-la-mediana.html#supuestos-12" id="toc-supuestos-12"><span class="toc-section-number">15.2</span> Supuestos</a></li>
<li><a href="prueba-de-la-mediana.html#estadístico-de-prueba-12" id="toc-estadístico-de-prueba-12"><span class="toc-section-number">15.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-la-mediana.html#hipótesis-12" id="toc-hipótesis-12"><span class="toc-section-number">15.4</span> Hipótesis</a></li>
<li><a href="prueba-de-la-mediana.html#comparación-múltiple-1" id="toc-comparación-múltiple-1"><span class="toc-section-number">15.5</span> Comparación Múltiple</a>
<ul>
<li><a href="prueba-de-la-mediana.html#ejercicio-2" id="toc-ejercicio-2"><span class="toc-section-number">15.5.1</span> Ejercicio</a></li>
</ul></li>
<li><a href="prueba-de-la-mediana.html#ejemplo-en-r-studio-12" id="toc-ejemplo-en-r-studio-12"><span class="toc-section-number">15.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-la-mediana.html#ejercicios-9" id="toc-ejercicios-9"><span class="toc-section-number">15.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="#part-bondad-de-ajuste" id="toc-part-bondad-de-ajuste">(PART) Bondad de Ajuste</a></li>
<li><a href="introducción-4.html#introducción-4" id="toc-introducción-4">Introducción</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#prueba-de-la-ji-cuadrada" id="toc-prueba-de-la-ji-cuadrada"><span class="toc-section-number">16</span> Prueba de la Ji-cuadrada</a>
<ul>
<li><a href="prueba-de-la-ji-cuadrada.html#datos-14" id="toc-datos-14"><span class="toc-section-number">16.1</span> Datos</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#hipótesis-13" id="toc-hipótesis-13"><span class="toc-section-number">16.2</span> Hipótesis</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#estadístico-de-prueba-13" id="toc-estadístico-de-prueba-13"><span class="toc-section-number">16.3</span> Estadístico de Prueba</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejemplo-11" id="toc-ejemplo-11"><span class="toc-section-number">16.4</span> Ejemplo</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejemplo-en-r-studio-13" id="toc-ejemplo-en-r-studio-13"><span class="toc-section-number">16.5</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-de-la-ji-cuadrada.html#ejercicios-10" id="toc-ejercicios-10"><span class="toc-section-number">16.6</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#prueba-kolmogorov" id="toc-prueba-kolmogorov"><span class="toc-section-number">17</span> Prueba Kolmogorov</a>
<ul>
<li><a href="prueba-kolmogorov.html#datos-15" id="toc-datos-15"><span class="toc-section-number">17.1</span> Datos</a></li>
<li><a href="prueba-kolmogorov.html#supuestos-13" id="toc-supuestos-13"><span class="toc-section-number">17.2</span> Supuestos</a></li>
<li><a href="prueba-kolmogorov.html#estadístico-de-prueba-14" id="toc-estadístico-de-prueba-14"><span class="toc-section-number">17.3</span> Estadístico de Prueba</a>
<ul>
<li><a href="prueba-kolmogorov.html#caso-a-prueba-de-2-colas" id="toc-caso-a-prueba-de-2-colas">Caso A (Prueba de 2 colas)</a></li>
<li><a href="prueba-kolmogorov.html#caso-b-prueba-de-1-cola" id="toc-caso-b-prueba-de-1-cola">Caso B (Prueba de 1 cola)</a></li>
<li><a href="prueba-kolmogorov.html#caso-c-prueba-de-1-cola" id="toc-caso-c-prueba-de-1-cola">Caso C (Prueba de 1 cola)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#hipótesis-14" id="toc-hipótesis-14"><span class="toc-section-number">17.4</span> Hipótesis</a>
<ul>
<li><a href="prueba-kolmogorov.html#caso-a-prueba-de-2-colas-1" id="toc-caso-a-prueba-de-2-colas-1">Caso A (Prueba de 2 colas)</a></li>
<li><a href="prueba-kolmogorov.html#caso-b-prueba-de-1-cola-1" id="toc-caso-b-prueba-de-1-cola-1">Caso B (Prueba de 1 cola)</a></li>
<li><a href="prueba-kolmogorov.html#caso-c-prueba-de-1-cola-1" id="toc-caso-c-prueba-de-1-cola-1">Caso C (Prueba de 1 cola)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov.html#ejemplo-12" id="toc-ejemplo-12"><span class="toc-section-number">17.5</span> Ejemplo</a></li>
<li><a href="prueba-kolmogorov.html#ejemplo-en-r-studio-14" id="toc-ejemplo-en-r-studio-14"><span class="toc-section-number">17.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-kolmogorov.html#otro-ejemplo-en-r" id="toc-otro-ejemplo-en-r"><span class="toc-section-number">17.7</span> Otro ejemplo en R</a></li>
<li><a href="prueba-kolmogorov.html#ejercicios-11" id="toc-ejercicios-11"><span class="toc-section-number">17.8</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-kolmogorov-smirnov.html#prueba-kolmogorov-smirnov" id="toc-prueba-kolmogorov-smirnov"><span class="toc-section-number">18</span> Prueba Kolmogorov-Smirnov</a>
<ul>
<li><a href="prueba-kolmogorov-smirnov.html#hipótesis-15" id="toc-hipótesis-15"><span class="toc-section-number">18.1</span> Hipótesis</a>
<ul>
<li><a href="prueba-kolmogorov-smirnov.html#caso-a-prueba-de-2-colas-2" id="toc-caso-a-prueba-de-2-colas-2"><span class="toc-section-number">18.1.1</span> Caso A (Prueba de 2 colas)</a></li>
</ul></li>
<li><a href="prueba-kolmogorov-smirnov.html#ejemplo-13" id="toc-ejemplo-13"><span class="toc-section-number">18.2</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-lilliefors-para-normalidad.html#prueba-lilliefors-para-normalidad" id="toc-prueba-lilliefors-para-normalidad"><span class="toc-section-number">19</span> Prueba Lilliefors para Normalidad</a>
<ul>
<li><a href="prueba-lilliefors-para-normalidad.html#datos-16" id="toc-datos-16"><span class="toc-section-number">19.1</span> Datos</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#supuestos-14" id="toc-supuestos-14"><span class="toc-section-number">19.2</span> Supuestos</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#hipótesis-16" id="toc-hipótesis-16"><span class="toc-section-number">19.3</span> Hipótesis</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#estadístico-de-prueba-15" id="toc-estadístico-de-prueba-15"><span class="toc-section-number">19.4</span> Estadístico de Prueba</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejemplo-14" id="toc-ejemplo-14"><span class="toc-section-number">19.5</span> Ejemplo</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejemplo-en-r-studio-15" id="toc-ejemplo-en-r-studio-15"><span class="toc-section-number">19.6</span> Ejemplo en R-Studio</a></li>
<li><a href="prueba-lilliefors-para-normalidad.html#ejercicios-12" id="toc-ejercicios-12"><span class="toc-section-number">19.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="pueba-de-lilliefors-exponencial.html#pueba-de-lilliefors-exponencial" id="toc-pueba-de-lilliefors-exponencial"><span class="toc-section-number">20</span> Pueba de Lilliefors Exponencial</a>
<ul>
<li><a href="pueba-de-lilliefors-exponencial.html#datos-17" id="toc-datos-17"><span class="toc-section-number">20.1</span> Datos</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#supuestos-15" id="toc-supuestos-15"><span class="toc-section-number">20.2</span> Supuestos</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#hipótesis-17" id="toc-hipótesis-17"><span class="toc-section-number">20.3</span> Hipótesis</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#estadistico-de-prueba" id="toc-estadistico-de-prueba"><span class="toc-section-number">20.4</span> Estadistico de Prueba</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejemplo-15" id="toc-ejemplo-15"><span class="toc-section-number">20.5</span> Ejemplo</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejemplo-en-r-studio-16" id="toc-ejemplo-en-r-studio-16"><span class="toc-section-number">20.6</span> Ejemplo en R-Studio</a></li>
<li><a href="pueba-de-lilliefors-exponencial.html#ejercicios-13" id="toc-ejercicios-13"><span class="toc-section-number">20.7</span> Ejercicios</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#prueba-anderson-darling" id="toc-prueba-anderson-darling"><span class="toc-section-number">21</span> Prueba Anderson-Darling</a>
<ul>
<li><a href="prueba-anderson-darling.html#datos-18" id="toc-datos-18"><span class="toc-section-number">21.1</span> Datos</a></li>
<li><a href="prueba-anderson-darling.html#supuestos-16" id="toc-supuestos-16"><span class="toc-section-number">21.2</span> Supuestos</a></li>
<li><a href="prueba-anderson-darling.html#hipótesis-18" id="toc-hipótesis-18"><span class="toc-section-number">21.3</span> Hipótesis</a>
<ul>
<li><a href="prueba-anderson-darling.html#caso-a-prueba-de-2-colas-solo-será-este-caso" id="toc-caso-a-prueba-de-2-colas-solo-será-este-caso">Caso A (Prueba de 2 colas) Solo será este caso</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#estadístico-de-prueba-16" id="toc-estadístico-de-prueba-16"><span class="toc-section-number">21.4</span> Estadístico de Prueba</a></li>
<li><a href="prueba-anderson-darling.html#regla-de-decisión-34" id="toc-regla-de-decisión-34"><span class="toc-section-number">21.5</span> Regla de Decisión</a>
<ul>
<li><a href="prueba-anderson-darling.html#ejemplo-16" id="toc-ejemplo-16"><span class="toc-section-number">21.5.1</span> Ejemplo</a></li>
</ul></li>
<li><a href="prueba-anderson-darling.html#ejemplo-en-r-studio-17" id="toc-ejemplo-en-r-studio-17"><span class="toc-section-number">21.6</span> Ejemplo en R-Studio</a></li>
</ul></li>
<li><a href="otras-estadísticas.html#otras-estadísticas" id="toc-otras-estadísticas"><span class="toc-section-number">22</span> Otras estadísticas</a>
<ul>
<li><a href="otras-estadísticas.html#mas-ejercicios" id="toc-mas-ejercicios"><span class="toc-section-number">22.1</span> Mas ejercicios</a></li>
</ul></li>
<li><a href="#part-regresión-lineal-simple" id="toc-part-regresión-lineal-simple">(PART) Regresión Lineal Simple</a></li>
<li><a href="introducción-5.html#introducción-5" id="toc-introducción-5">Introducción</a></li>
<li><a href="modelo-con-intercepto.html#modelo-con-intercepto" id="toc-modelo-con-intercepto"><span class="toc-section-number">23</span> Modelo con intercepto</a>
<ul>
<li><a href="modelo-con-intercepto.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo"><span class="toc-section-number">23.1</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-con-intercepto.html#propiedades-de-los-estimadores" id="toc-propiedades-de-los-estimadores"><span class="toc-section-number">23.2</span> Propiedades de los estimadores</a></li>
</ul></li>
<li><a href="modelo-sin-intercepto.html#modelo-sin-intercepto" id="toc-modelo-sin-intercepto"><span class="toc-section-number">24</span> Modelo sin intercepto</a>
<ul>
<li><a href="modelo-sin-intercepto.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-1" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-1"><span class="toc-section-number">24.1</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-sin-intercepto.html#propiedades-de-los-estimadores-1" id="toc-propiedades-de-los-estimadores-1"><span class="toc-section-number">24.2</span> Propiedades de los estimadores</a>
<ul>
<li><a href="modelo-sin-intercepto.html#ejemplo-en-r-studio-18" id="toc-ejemplo-en-r-studio-18"><span class="toc-section-number">24.2.1</span> Ejemplo en R-Studio</a></li>
</ul></li>
</ul></li>
<li><a href="intervalos-de-confianza-1.html#intervalos-de-confianza-1" id="toc-intervalos-de-confianza-1"><span class="toc-section-number">25</span> Intervalos de confianza</a>
<ul>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-beta_0" id="toc-intervalo-para-beta_0"><span class="toc-section-number">25.1</span> Intervalo para <span class="math inline">\(\beta_{0}\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-beta_1" id="toc-intervalo-para-beta_1"><span class="toc-section-number">25.2</span> Intervalo para <span class="math inline">\(\beta_{1}\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-sigma2" id="toc-intervalo-para-sigma2"><span class="toc-section-number">25.3</span> Intervalo para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-para-el-valor-esperado-y" id="toc-intervalo-para-el-valor-esperado-y"><span class="toc-section-number">25.4</span> Intervalo para el valor esperado <span class="math inline">\(y\)</span></a></li>
<li><a href="intervalos-de-confianza-1.html#intervalo-de-predicción" id="toc-intervalo-de-predicción"><span class="toc-section-number">25.5</span> Intervalo de predicción</a>
<ul>
<li><a href="intervalos-de-confianza-1.html#ejemplo-17" id="toc-ejemplo-17"><span class="toc-section-number">25.5.1</span> Ejemplo</a></li>
</ul></li>
</ul></li>
<li><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis" id="toc-pruebas-de-hipótesis"><span class="toc-section-number">26</span> Pruebas de hipótesis</a>
<ul>
<li><a href="pruebas-de-hipótesis.html#pruebas-para-beta_0" id="toc-pruebas-para-beta_0"><span class="toc-section-number">26.1</span> Pruebas para <span class="math inline">\(\beta_{0}\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#prueba-para-beta_1" id="toc-prueba-para-beta_1"><span class="toc-section-number">26.2</span> Prueba para <span class="math inline">\(\beta_{1}\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#prueba-para-sigma2" id="toc-prueba-para-sigma2"><span class="toc-section-number">26.3</span> Prueba para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#análisis-de-la-varianza-anova" id="toc-análisis-de-la-varianza-anova"><span class="toc-section-number">26.4</span> Análisis de la varianza (ANOVA)</a></li>
<li><a href="pruebas-de-hipótesis.html#coeficiente-de-determinación" id="toc-coeficiente-de-determinación"><span class="toc-section-number">26.5</span> Coeficiente de determinación</a></li>
<li><a href="pruebas-de-hipótesis.html#propiedades-de-r2" id="toc-propiedades-de-r2"><span class="toc-section-number">26.6</span> Propiedades de <span class="math inline">\(R^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis.html#relación-r2-y-la-correlación-de-pearson" id="toc-relación-r2-y-la-correlación-de-pearson"><span class="toc-section-number">26.7</span> Relación <span class="math inline">\(R^2\)</span> y la correlación de Pearson</a>
<ul>
<li><a href="pruebas-de-hipótesis.html#ejemplo-18" id="toc-ejemplo-18"><span class="toc-section-number">26.7.1</span> Ejemplo</a></li>
</ul></li>
</ul></li>
<li><a href="validación-de-supuestos.html#validación-de-supuestos" id="toc-validación-de-supuestos"><span class="toc-section-number">27</span> Validación de supuestos</a>
<ul>
<li><a href="validación-de-supuestos.html#análisis-de-residuales" id="toc-análisis-de-residuales"><span class="toc-section-number">27.1</span> Análisis de residuales</a></li>
<li><a href="validación-de-supuestos.html#supuesto-de-normalidad" id="toc-supuesto-de-normalidad"><span class="toc-section-number">27.2</span> Supuesto de normalidad</a>
<ul>
<li><a href="validación-de-supuestos.html#validación-del-supuesto-de-normalidad" id="toc-validación-del-supuesto-de-normalidad"><span class="toc-section-number">27.2.1</span> Validación del supuesto de normalidad</a></li>
</ul></li>
<li><a href="validación-de-supuestos.html#supuesto-de-linealidad" id="toc-supuesto-de-linealidad"><span class="toc-section-number">27.3</span> Supuesto de linealidad</a></li>
<li><a href="validación-de-supuestos.html#supuesto-de-homocedasticidad" id="toc-supuesto-de-homocedasticidad"><span class="toc-section-number">27.4</span> Supuesto de homocedasticidad</a>
<ul>
<li><a href="validación-de-supuestos.html#prueba-de-breusch-pagan" id="toc-prueba-de-breusch-pagan"><span class="toc-section-number">27.4.1</span> Prueba de Breusch-Pagan</a></li>
<li><a href="validación-de-supuestos.html#prueba-de-white" id="toc-prueba-de-white"><span class="toc-section-number">27.4.2</span> Prueba de White</a></li>
<li><a href="validación-de-supuestos.html#ejemplo-19" id="toc-ejemplo-19"><span class="toc-section-number">27.4.3</span> Ejemplo</a></li>
</ul></li>
<li><a href="validación-de-supuestos.html#valores-outlier-e-influyentes" id="toc-valores-outlier-e-influyentes"><span class="toc-section-number">27.5</span> Valores outlier e influyentes</a>
<ul>
<li><a href="validación-de-supuestos.html#valores-outlier" id="toc-valores-outlier"><span class="toc-section-number">27.5.1</span> Valores outlier</a></li>
<li><a href="validación-de-supuestos.html#valores-influentes" id="toc-valores-influentes"><span class="toc-section-number">27.5.2</span> Valores influentes</a></li>
</ul></li>
</ul></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#modelo-de-regresión-lineal-múltiple" id="toc-modelo-de-regresión-lineal-múltiple"><span class="toc-section-number">28</span> Modelo de regresión lineal múltiple</a>
<ul>
<li><a href="modelo-de-regresión-lineal-múltiple.html#introducción-6" id="toc-introducción-6"><span class="toc-section-number">28.1</span> Introducción</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#modelo-de-regresión-lineal-múltiple-1" id="toc-modelo-de-regresión-lineal-múltiple-1"><span class="toc-section-number">28.2</span> Modelo de regresión lineal múltiple</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-2" id="toc-estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo-2"><span class="toc-section-number">28.3</span> Estimación por mínimos cuadrados de los parámetros del modelo</a></li>
<li><a href="modelo-de-regresión-lineal-múltiple.html#estimación-por-máxima-verosimilitud" id="toc-estimación-por-máxima-verosimilitud"><span class="toc-section-number">28.4</span> Estimación por máxima verosimilitud</a></li>
</ul></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-confianza-2" id="toc-intervalos-de-confianza-2"><span class="toc-section-number">29</span> Intervalos de confianza</a>
<ul>
<li><a href="intervalos-de-confianza-2.html#intervalo-para-beta_j" id="toc-intervalo-para-beta_j"><span class="toc-section-number">29.1</span> Intervalo para <span class="math inline">\(\beta_{j}\)</span></a></li>
<li><a href="intervalos-de-confianza-2.html#intervalo-para-sigma2-1" id="toc-intervalo-para-sigma2-1"><span class="toc-section-number">29.2</span> Intervalo para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-la-respuesta-media" id="toc-intervalos-de-la-respuesta-media"><span class="toc-section-number">29.3</span> Intervalos de la respuesta media</a></li>
<li><a href="intervalos-de-confianza-2.html#intervalos-de-predicción" id="toc-intervalos-de-predicción"><span class="toc-section-number">29.4</span> Intervalos de predicción</a></li>
</ul></li>
<li><a href="pruebas-de-hipótesis-1.html#pruebas-de-hipótesis-1" id="toc-pruebas-de-hipótesis-1"><span class="toc-section-number">30</span> Pruebas de hipótesis</a>
<ul>
<li><a href="pruebas-de-hipótesis-1.html#región-de-rechazo-para-beta_j" id="toc-región-de-rechazo-para-beta_j"><span class="toc-section-number">30.1</span> Región de rechazo para <span class="math inline">\(\beta_{j}\)</span></a></li>
<li><a href="pruebas-de-hipótesis-1.html#prueba-para-sigma2-1" id="toc-prueba-para-sigma2-1"><span class="toc-section-number">30.2</span> Prueba para <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="pruebas-de-hipótesis-1.html#análisis-de-la-varianza-anova-1" id="toc-análisis-de-la-varianza-anova-1"><span class="toc-section-number">30.3</span> Análisis de la varianza (ANOVA)</a></li>
<li><a href="pruebas-de-hipótesis-1.html#coeficiente-de-determinación-2" id="toc-coeficiente-de-determinación-2"><span class="toc-section-number">30.4</span> Coeficiente de determinación</a></li>
<li><a href="pruebas-de-hipótesis-1.html#r2-ajustado" id="toc-r2-ajustado"><span class="toc-section-number">30.5</span> <span class="math inline">\(R^2\)</span> ajustado</a></li>
</ul></li>
<li><a href="validación-de-supuestos-1.html#validación-de-supuestos-1" id="toc-validación-de-supuestos-1"><span class="toc-section-number">31</span> Validación de supuestos</a>
<ul>
<li><a href="validación-de-supuestos-1.html#supuesto-de-multicolinealidad" id="toc-supuesto-de-multicolinealidad"><span class="toc-section-number">31.1</span> Supuesto de multicolinealidad</a></li>
<li><a href="validación-de-supuestos-1.html#detección-de-multicolinealidad" id="toc-detección-de-multicolinealidad"><span class="toc-section-number">31.2</span> Detección de multicolinealidad</a></li>
<li><a href="validación-de-supuestos-1.html#ejemplo-20" id="toc-ejemplo-20"><span class="toc-section-number">31.3</span> Ejemplo</a></li>
</ul></li>
<li><a href="apéndice.html#apéndice" id="toc-apéndice"><span class="toc-section-number">32</span> Apéndice</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Hecho con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos no paramétricos y de Regresión</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelo-con-intercepto" class="section level1" number="23">
<h1><span class="header-section-number">Capítulo 23</span> Modelo con intercepto</h1>
<p>El objetivo principal del <strong>Modelo de Regresión Lineal Simple</strong> es el poder asociar o ajustar a una dispersión de datos una función (en primera instancia se abordará el ajuste mediante una recta) cuyos parámetros dependan directamente de las observaciones con la finalidad de poder resumir, simplificar u obtener propiedades importantes sobre comportamiento de la muestra.</p>
<p>Dicho modelo es el más sencillo de los modelos lineales e involucra una variable de interés <span class="math inline">\(y\)</span> llamada <strong>dependiente</strong> o <strong>respuesta</strong> y su relación con la variable <strong>predictoria</strong> o <strong>independiente</strong> <span class="math inline">\(x\)</span>, estableciendo que la media de la variable dependiente <span class="math inline">\(y\)</span> cambia a razón constante cuando el valor de la variable independiente <span class="math inline">\(x\)</span> crece o decrece.</p>
<p>El modelo de regresión lineal simple en general es:</p>
<p><span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i},\]</span>
donde:</p>
<ul>
<li><p>x es la variable regresora,</p></li>
<li><p>y es la variable de respuesta,</p></li>
<li><p><span class="math inline">\(\beta_{0}\)</span> ordenada al origen,</p></li>
<li><p><span class="math inline">\(\beta_{1}\)</span> pendiente del modelo,</p></li>
<li><p><span class="math inline">\(\epsilon\)</span> es un error aleatorio.</p></li>
</ul>
<p>Conviene considerar a la variable regresora <span class="math inline">\(x\)</span> como una varible determinista, o bien, una variable controlada por el investigador la cual puede ser medida, mientras que la variable respuesta <span class="math inline">\(y\)</span> es una variable aleatoria. Ahora bien, los datos no caen exactamente sobre una recta por lo que se considera <span class="math inline">\(\epsilon\)</span> como un error estadístico, esto es, que es una variable aleatoria que explica por qué el modelo no ajusta exactamente los datos.</p>
<p>Una vez vista la ecuación general del modelo de regresión lineal simple se hablará de algunos supuestos que se deben de cumplir al ajustar una serie de datos, éstas consideraciones hace que en ocaciones carezca de sentido realizar una regresión lineal, sin embargo, no hay que perder de vista que éste es un modelado por lo que algunas características físicas del problema pueden haber sido simplificadas u omitidas.</p>
<p><strong>Definición 2.1</strong> (Supuestos del Modelo de Regresión Simple).</p>
<p>En el modelo de regresión simple se supone que <span class="math inline">\(\epsilon\)</span> satisface:</p>
<ul>
<li><p><span class="math inline">\(\mathbf{E}[\epsilon_{i}]=0\)</span></p></li>
<li><p><span class="math inline">\(\textbf{Var}(\epsilon_{i})=\sigma^2\)</span></p></li>
<li><p><span class="math inline">\(\textbf{Cov}(\epsilon_{i},\epsilon_{j})= 0 \  \ \ \forall \ i = 1, \ldots, n, \ \  j=1, \ldots, n, \ \  i \neq j.\)</span></p></li>
<li><p><span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span></p></li>
</ul>
<p>Una vez considerados estos supuestos se pueden obtener resultados aún más importantes.</p>
<p>Por ejemplo, con los supuestos dados es posible calcular la esperanza y la varianza de la variable <span class="math inline">\(y_{i}\)</span>, dado un valor <span class="math inline">\(x_{i}\)</span>.</p>
<p><strong>Teorema 2.1</strong> Sea <span class="math inline">\(y\)</span> una variable de interés, denominada variable de respuesta, la cual es relacionada con una variable regresora <span class="math inline">\(x\)</span>, entonces:</p>
<p><strong>a)</strong> <span class="math inline">\(\mathbf{E}[y_{i}]=\beta_{0}+\beta_{1}x_{i}\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(\textbf{Var}(y_{i})=\sigma^2\)</span></p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong></p>
<p><span class="math display">\[\mathbf{E}[y_{i}]=\mathbf{E}[\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}]\]</span></p>
<p>La parte aleatoria de <span class="math inline">\(y_{i}\)</span> es <span class="math inline">\(\epsilon_{i}\)</span>;   <span class="math inline">\(\beta_{0}\)</span>,<span class="math inline">\(\beta_{1}\)</span> son constantes y <span class="math inline">\(x_{i}\)</span> ya es un valor dado; por lo que:</p>
<p><span class="math display">\[\mathbf{E}[y_{i}]=\beta_{0}+\beta_{1}x_{i}+\mathbf{E}[\epsilon_{i}]\]</span></p>
<p><span class="math display">\[=\beta_{0}+\beta_{1}x_{i}+0\]</span>
<span class="math display">\[\therefore \mathbf{E}[y_{i}]=\beta_{0}+\beta_{1}x_{i}.\]</span>
<strong>b)</strong></p>
<p><span class="math display">\[Var(y_{i})= Var(\beta_{0}+\beta_{1}x_{i}+\epsilon{i})\]</span>
La parte aleatoria de <span class="math inline">\(y_{i}\)</span> es <span class="math inline">\(\epsilon_{i}\)</span>; <span class="math inline">\(\beta_{0}\)</span>,<span class="math inline">\(\beta_{1}\)</span> son constantes y <span class="math inline">\(x_{i}\)</span> ya es un valor dado; por lo que <span class="math inline">\(Var(c+\epsilon_{i})=Var(\epsilon_{i})\)</span> con <span class="math inline">\(c\)</span> constante, de esta manera:</p>
<p><span class="math display">\[Var(y_{i})=0+0+Var(\epsilon_{i})\]</span>
<span class="math display">\[\therefore Var(y_{i})=\sigma^2\]</span></p>
<div id="estimación-por-mínimos-cuadrados-de-los-parámetros-del-modelo" class="section level2" number="23.1">
<h2><span class="header-section-number">23.1</span> Estimación por mínimos cuadrados de los parámetros del modelo</h2>
<p>El modelo de regresión lineal simple</p>
<p><span class="math display">\[y=\beta_{0}+\beta_{1}x+\epsilon\]</span></p>
<p>cuenta con dos parámetros desconocidos, <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span>, los cuales deben ser estimados a partir de los datos de la muestra. Con la hipótesis de varianza constante sobre los errores, aparece otro parámetro <span class="math inline">\(\sigma^2\)</span> desconocido, aunque no está incluido en el modelo también debe ser estimado.
Un procedimiento para estimar los parámetros de un modelo lineal simple es el <strong>método de mínimos cuadrados</strong>, que se puede ilustar sencillamente aplicándolo para ajustar una línea recta a <span class="math inline">\((x_{1},y_{1}),(x_{2},y_{2}),\ldots,(x_{n},y_{n})\)</span>, se estiman <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> tales que la suma de los cuadrados de las diferencias entre las observaciones <span class="math inline">\(y_{i}\)</span> y la línea recta sea mínima.</p>
<p><strong>Definición 2.2</strong> (Residuos). Sea <span class="math inline">\(y_{i}\)</span> los valores observados, <span class="math inline">\(\hat{y_{i}}\)</span> los valores estimados mediante la regresión lineal simple. La forma de calcular la desviación de <span class="math inline">\(y_{i}\)</span> con respecto a su media estimada <span class="math inline">\(\hat{y_{i}}=\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}\)</span> para un <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> dados es:</p>
<p><span class="math display">\[e_{i}=y_{i}-\hat{y_{i}}\]</span>
donde <span class="math inline">\(e_{i}\)</span> son los residuos.</p>
<p>Por lo anterior,</p>
<p><span class="math display">\[e_{i}=y_{i}-\hat{\beta_{0}}-\hat{\beta_{1}}x_{i}\]</span>
Como se mencionó, lo que se busca es que la diferencia entre todos los valores observados y los valores estimados sea 0, es decir, que la suma de distancias entre <span class="math inline">\(y_{i}\)</span> y <span class="math inline">\(\hat{y_{i}}\)</span> sea cero, lo anterior significa que:</p>
<p><span class="math display">\[\sum_{i=1}^{n}e_{i}=0\]</span>
Para estimar <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> el <strong>método de mínimos cuadrados</strong> propone minimizar la suma de los cuadrados de los residuos, ya que de ésta manera se minimizan las distancias verticales entre las observaciones reales <span class="math inline">\((y)\)</span> y las estimadas <span class="math inline">\((\hat{y})\)</span>, ya que entre más cercanas a cero se encuentren las distancias, mejor se ajusta el modelo a los datos.
Antes de continuar, es necesario abordar unos cuantos resultados.</p>
<p>Se define a:</p>
<p><span class="math display">\[S_{xx}=\sum_{i=1}^{n}(x_{i}-\overline{x})^{2}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}(x_{i}^2-2x_{i}\overline{x}+\overline{x}_{i}^{2})\]</span>
<span class="math display">\[=\sum_{i=1}^{n}x_{i}^{2}-\sum_{i=1}^{n}2x_{i}\overline{x}+\sum_{i=1}^{n}\overline{x}_{i}^2\]</span>
<span class="math display">\[=\sum_{i=1}^{n}x_{i}^2-2\overline{x}^2n+\overline{x}_{i}^2n\]</span></p>
<p><span class="math display">\[S_{xx}=\sum_{i=1}^{n}x_{i}^2-\overline{x}^2n.\]</span></p>
<p>También definimos:</p>
<p><span class="math display">\[S_{xy}=\sum_{i=1}^{n}(xi-\overline{x})(y_{i}-\overline{y})\]</span></p>
<p><span class="math display">\[=\sum_{i=1}^{n}(x_{i}-\overline{x})y_{i}\]</span></p>
<p><span class="math display">\[=\sum_{i=1}^{n}x_{i}(y_{i}-\overline{y})\]</span>
<span class="math display">\[=\sum_{i=1}^{n}X_{i}y_{i}-\left(\sum_{i=1}^{n}x_{i}\right) \left(\sum_{i=1}^{n}y_{i}\right) \ /{n}\]</span></p>
<p><span class="math display">\[S_{xy}=\sum_{i=1}^{n}x_{i}y_{i}-n\overline{x}\overline{y}\]</span></p>
<p>Una vez definida la notación, tenemos el siguiente teorema:</p>
<p><strong>Teorema 2.2</strong> (Mínimos Cuadrados). Sea <span class="math inline">\(\hat{\beta_0}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> los parámetros que minimizan la suma de cuadrados de la diferencia entre los valores observados y los estimados <span class="math inline">\(\left(\sum_{i=1}^{n}e_i^2\right)\)</span> entonces:</p>
<p><strong>a)</strong> <span class="math inline">\(\hat{\beta_{0}}=\overline{y}-\hat{\beta_{1}}\overline{x}\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(\hat{\beta_{1}}=\frac{S_{xy}}{S_{xx}}=\frac{\sum_{i=1}^{n}(x_{i}-\overline{x})(y_{i}-\overline{y})}{\sum_{i=1}^{n}(x_{i}-\overline{x})^2}\)</span></p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong></p>
<p>Tenemos:</p>
<p><span class="math display">\[\sum_{i=1}^{n}e_{i}^2=\sum_{i=1}^{n}(y_{i}-\hat{\beta_{0}}-\hat{\beta_{1}}x_{i})^2.\]</span>
Minimizando la suma de cuadrados, se deriva respecto a <span class="math inline">\(\hat{\beta_{0}}\)</span></p>
<p><span class="math display">\[\frac{\delta\sum_{i=1}^{n}e_{i}^2}{\delta\hat{\beta_{0}}}=-2\sum_{i=1}^{n}(y_{i}-\hat{\beta_{0}}-\hat{\beta_{1}}x_{i})\]</span>
<span class="math display">\[\frac{\delta\sum_{i=1}^{n}e_{i}^2}{\delta\hat{\beta_{0}}}=-2\left(\sum_{i=1}^{n}y_{i}-\sum_{i=1}^{n}\hat{\beta_{0}}-\sum_{i=1}^{n}\hat{\beta_{1}x_{i}}\right).\]</span>
Igualando a 0</p>
<p><span class="math display">\[-2\left(\sum_{i=1}^{n}y_{i}-\hat{\beta_{0}}n-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}\right)=0\]</span>
<span class="math display">\[\sum_{i=1}^{n}y_{i}-\hat{\beta_{0}}n-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}=0\]</span>
<span class="math display">\[\sum_{i=1}^{n}y_{i}=n\hat{\beta_{0}}+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}\]</span>
<span class="math display">\[\overline{y}n=n\hat{\beta_{0}}+\hat{\beta_{1}}\overline{x}n\]</span>
<span class="math display">\[\overline{y}=\hat{\beta_{0}}+\hat{\beta_{1}}\overline{x}\]</span>
<span class="math display">\[\therefore\hat{\beta_{0}}=\overline{y}-\hat{\beta_{1}}\overline{x}.\blacksquare\]</span>
Por lo tanto se obtiene el primer estimador, <span class="math inline">\(\hat{\beta_{0}}\)</span>; para el estimador de <span class="math inline">\(\beta_{1}\)</span> se deriva respecto a <span class="math inline">\(\hat{\beta_{1}}\)</span>:</p>
<p><span class="math display">\[\frac{\delta\sum_{i=1}^{n}e_{i}^2}{\delta\hat{\beta_{1}}}=-2\sum_{i=1}^{n}(y_{i}-\hat{\beta_{0}}-\hat{\beta_{1}}x_{i})x_{i}\]</span>
<span class="math display">\[=-2\left(\sum_{i=1}^{n}x_{i}y_{i}-\sum_{i=1}^{n}\hat{\beta_{0}}x_{i}-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}^2\right).\]</span>
Igualando la derivada a 0 para hallar el punto crítico</p>
<p><span class="math display">\[-2\left(\sum_{i=1}^{n}x_{i}y_{i}-\sum_{i=1}^{n}\hat{\beta_{0}}x_{i}-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}^2\right)=0\]</span></p>
<p><span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}-\sum_{i=1}^{n}\hat{\beta_{0}}x_{i}-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}^2=0\]</span>
<span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}=\sum_{i=1}^{n}\hat{\beta_{0}}x_{i}+\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}^2\]</span>
<span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}=\hat{\beta_{0}}\sum_{i=1}^{n}x_{i}+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}^2\]</span>
<span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}=\hat{\beta_{0}}\overline{x}n+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}^2\]</span>
Sustituyendo <span class="math inline">\(\hat{\beta_{0}}\)</span> por <span class="math inline">\(\overline{y}-\hat{\beta_{1}}\overline{x}\)</span> se tiene:</p>
<p><span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}=\overline{y}\overline{x}n-\hat{\beta_{1}}\overline{x}^2n+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}^2\]</span>
<span class="math display">\[\sum_{i=1}^{n}x_{i}y_{i}-\overline{y}\overline{x}n+\hat{\beta_{1}}\overline{x}^2n-\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}^2\]</span>
Por la notación tenemos que: <span class="math inline">\(S_{xy}=\sum x_{i}y_{i} - n \overline{x}\overline{y}\)</span> y <span class="math inline">\(S_{xx}= \sum x_{i}^2 - n\overline{x}^2\)</span></p>
<p><span class="math display">\[\frac{\delta \sum_{i=1}^{n}e_{i}^2}{\delta\hat{\beta_{1}}}=-2\left(S_{xy}-\hat{\beta_{1}\left(\sum_{i=1}^{n}x_{i}^2-\overline{x}^2n\right)}\right)\]</span>
<span class="math display">\[=-2(S_{xy}-\hat{\beta_{1}}S_{xx}).\]</span>
Igualando a 0</p>
<p><span class="math display">\[-2(S_{xy}-\hat{\beta_{1}}S_{xx})=0\]</span>
<span class="math display">\[S_{xy}-\hat{\beta_{1}}S_{xx}=0\]</span>
<span class="math display">\[\Rightarrow \hat{\beta_{1}}=\frac{S_{xy}}{S_{xx}}\]</span>
<span class="math display">\[\therefore \hat{\beta_{1}}=\frac{\sum_{i=1}^{n}(x_{i}-\overline{x})(y_{i}-\overline{y})}{\sum_{i=1}^{n}(x_{i}-\overline{x})^2}.\blacksquare\]</span>
De esta manera se demuestra el teorema 2.2. Un punto a destacar es que las siguientes ecuaciones:</p>
<p><span class="math display">\[
\left\{
\begin{array}{ll} \hat{\beta_{0}} \ \ n  \ \ \  \ \ \ \ \ \ + \ \hat{\beta_{1}}\sum_{i=1}^{n}x_{i}\  \ = \ \sum_{i=1}^{n}y_{i} \\
\\
\hat{\beta_{0}} \ \sum_{i=1}^{n}x_{i} \ + \ \hat{\beta_{1}}\sum_{i=1}^{n}x_{i}^2 \ \ = \ \sum_{i=1}^{n}x_{i}y_{i}
\end{array}
\right.
\]</span></p>
<p>Son conocidas como las <strong>ecuaciones normales</strong>, que en conjunto forman un sistema de ecuaciones; al resolverlas simultáneamente para <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> se obtiene los estimadores de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> que se plantean en el teorema anterior.</p>
<p>Un problema del método de mínimos cuadrados es que no proporciona un estimador para <span class="math inline">\(\sigma^2\)</span>, sin embargo, se obtendrá bajo el supuesto de normalidad que es el siguiente:</p>
<p><span class="math display">\[\hat{\sigma}^2=\frac{1}{n-2}\sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^2\]</span>
De esta manera se ha cumplido el objetivo que se planteó al inicio, encontrar los estimadores de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> tal que los residuales fueran igual a 0.</p>
<p><strong>Teorema 2.3</strong> (Diferencia de Residuales) Sea <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> los estimadores de mínimos cuadrados de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span>, respectivamente, entonces la suma de las distancias entre <span class="math inline">\(y_{i}\)</span> y <span class="math inline">\(\hat{y_{i}}\)</span> es cero, es decir:</p>
<p><span class="math display">\[\sum_{i=1}^{n}e_{i}=0\]</span></p>
<p><strong>Demostración</strong></p>
<p>Tenemos que el residual <span class="math inline">\(e_{i}\)</span> se calcula como: <span class="math inline">\(e_{i}=y_{i}-\hat{\beta_{0}}-\hat{\beta_1}x_{i}\)</span> entonces si sustituimos se tiene:</p>
<p><span class="math display">\[\sum_{i=1}^{n}e_{i}=\sum_{i=1}^{n}\left(y_{i}-\hat{\beta_{0}}-\hat{\beta_1}x_{i}\right)\]</span></p>
<p><span class="math display">\[=\sum_{i=1}^{n}y_{i}-\sum_{i=1}^{n}\hat{\beta_{0}}-\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}\]</span>
<span class="math display">\[=n\overline{y}-n\hat{\beta_{0}}-n\hat{\beta_{1}}\overline{x}\]</span>
<span class="math display">\[=n\left[\overline{y}-\hat{\beta_{0}}-\hat{\beta_{1}}\overline{x}\right]\]</span>
Recordando que la estimación de <span class="math inline">\(\hat{\beta_{0}}=\overline{y}-\hat{\beta_{1}}\overline{x}\)</span> tenemos:</p>
<p><span class="math display">\[=n\left[\overline{y}-\overline{y}+\hat{\beta_{1}}\overline{x}-\hat{\beta_{1}}\overline{x}\right]\]</span></p>
<p><span class="math inline">\(\therefore \sum_{i=1}^{n}e_{i}=0. \blacksquare\)</span></p>
<p>Esto implica que si la suma de residuales es 0, entonces la <span class="math inline">\(\sum_{i=1}^{n}\hat{y_{i}}=\sum_{i=1}^{n}y_{i}\)</span> y vamos a demostrarlo:</p>
<p><strong>Corolario 1</strong> Sea <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> los estimadores de mínimos cuadrados de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> respectivamente, si se cumple el teorema anterior, entonces la suma de los valores observados y la suma de los valores ajustados por la regresión son iguales, es decir:</p>
<p><span class="math display">\[\sum_{i=1}^{n}\hat{y_{i}}=\sum_{i=1}^{n}y_{i}\]</span></p>
<p><strong>Demostración</strong></p>
<p>Por definición:</p>
<p><span class="math display">\[\sum_{i=1}^{n}\hat{y_{i}}=\sum_{i=1}^{n}\left(\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}\right)\]</span>
Por la estimación de <span class="math inline">\(\hat{\beta_{1}}\)</span></p>
<p><span class="math display">\[=\sum_{i=1}^{n}\left(\overline{y}-\hat{\beta_{1}}\overline{x}+\hat{\beta_{1}}x_{i}\right)\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\overline{y}-n\hat{\beta_{1}}\overline{x}+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}\]</span>
<span class="math display">\[=n\overline{y}-n\hat{\beta_{1}}\overline{x}+n\hat{\beta_{1}}\overline{x}\]</span>
<span class="math display">\[=n\overline{y}\]</span>
Por construcción de <span class="math inline">\(\overline{y}\)</span></p>
<p><span class="math display">\[\therefore \sum_{i=1}^{n}\hat{y_{i}}=\sum_{i=1}^{n}y_{i}. \blacksquare\]</span></p>
<p>Una consecuencia de lo anterior,</p>
<p><strong>Corolario 2</strong> Sea <span class="math inline">\(\hat{y_{i}}\)</span> el valor estimado de la forma   <span class="math inline">\(\hat{y_{i}}=\hat{\beta_{0}}+\hat{\beta_{1}}x_{i}\)</span>   y el residual  <span class="math inline">\(e_{i}=y_{i}-\hat{y_{i}}\)</span>, entonces se cumple que:</p>
<p><span class="math display">\[\sum_{i=1}^{n}\hat{y_{i}}e_{i}=0\]</span></p>
<p><strong>Demostración</strong></p>
<p>Por definición de las <span class="math inline">\(\hat{y}\)</span></p>
<p><span class="math display">\[\sum_{i=1}^{n}\hat{y_{i}}e_{i}=\sum_{i=1}^{n}(\hat{\beta_{0}}+\hat{\beta_{1}}x_{i})e_{i}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\hat{\beta_{0}}e_{i}+\hat{\beta_{1}}x_{i}e_{i}\right)\]</span></p>
<p><span class="math display">\[=\sum_{i=1}^{n}\hat{\beta_{0}}e_{i}+\sum_{i=1}^{n}\hat{\beta_{1}}x_{i}e_{i}\]</span>
<span class="math display">\[=\hat{\beta_{0}}\sum_{i=1}^{n}e_{i}+\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}e_{i}\]</span>
Y como demostramos anteriormente, la suma de los residuos es cero:</p>
<p><span class="math display">\[=\hat{\beta_{1}}\sum_{i=1}^{n}x_{i}(y_{i}-\hat{y_{i}})\]</span>
<span class="math display">\[=\hat{\beta_{1}}\sum_{i=1}^{n}\left(x_{i}y_{i}-x_{i}\hat{\beta_{0}}-x_{i}^{2}\hat{\beta_{1}}\right)\]</span>
<span class="math display">\[=\hat{\beta_{1}}\sum_{i=1}^{n}\left(x_{i}y_{i}-x_{i}^2\hat{\beta_{1}}-x_{i}y_{i}+x_{i}^{2}\hat{\beta_{1}}\right)\]</span></p>
<p>Entonces:</p>
<p><span class="math display">\[\sum_{i=1}^{n}\hat{y_{i}}e_{i}=0. \blacksquare\]</span></p>
</div>
<div id="propiedades-de-los-estimadores" class="section level2" number="23.2">
<h2><span class="header-section-number">23.2</span> Propiedades de los estimadores</h2>
<p>Los estimadores <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span> tienen propiedades estadísticas muy importantes. ya que son estimadores insesgados, además son de mínima varianza. La propiedad de insesgamiento se revisará en el siguiente teorema:</p>
<p><strong>Teorema 2.4</strong> Sea <span class="math inline">\(\hat{\beta_{0}}\)</span>, <span class="math inline">\(\hat{\beta_{1}}\)</span> los estimadores de mínimos cuadrados de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span>, respectivamente, entonces los estimadores <span class="math inline">\(\hat{\beta_{0}}\)</span>,<span class="math inline">\(\hat{\beta_{1}}\)</span> son insesgados. Es decir:</p>
<p><strong>a)</strong> <span class="math inline">\(\mathbf{E}\left[\hat{\beta_{1}}\right]=\beta_{1}\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(\mathbf{E}\left[\hat{\beta_{0}}\right]=\beta_{0}\)</span></p>
<p><strong>Demostración</strong></p>
<p><strong>a)</strong> Para demostrar el insesgamiento de <span class="math inline">\(\hat{\beta_{1}}\)</span> usaremos la propiedad de combinación lineal de <span class="math inline">\(\beta_{1}:\)</span></p>
<p>“Haremos un pequeño paréntesis para demostrarlo”</p>
<p>Tenemos:</p>
<p><span class="math display">\[\hat{\beta_{1}}=\frac{S_{xy}}{S_{xx}}\]</span>
Sustituyendo <span class="math inline">\(S_{xx}\)</span> y <span class="math inline">\(S_{xy}\)</span></p>
<p><span class="math display">\[\hat{\beta_{1}}=\frac{\sum_{i=1}^{n}(x_{i}-\overline{x})y_{i}}{S_{xx}}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\frac{x_{i}-\overline{x}}{S_{xx}}\right)y_{i}.\]</span>
Haciendo <span class="math inline">\(a=\frac{(x_{i}-\overline{x})}{S_{xx}}\)</span> nada depende de <span class="math inline">\(y\)</span>, por lo que <span class="math inline">\(a\)</span> es constante, por consiguiente la combinación lineal de las <span class="math inline">\(y_{i}\)</span> para <span class="math inline">\(\hat{\beta_{1}}\)</span> es:</p>
<p><span class="math display">\[\therefore \hat{\beta_{1}}=\sum_{i=1}^{n}ay_{i}.\]</span>
Para la combinación lineal de las <span class="math inline">\(y_{i}\)</span> para <span class="math inline">\(\hat{\beta_{0}}\)</span> se tiene:</p>
<p><span class="math display">\[\hat{\beta_{0}}=\overline{y}-\hat{\beta_{1}}\overline{x}\]</span>
Sustituyendo la combinación lineal de <span class="math inline">\(\hat{\beta_{1}}\)</span> y notación de <span class="math inline">\(S_{xx}\)</span></p>
<p><span class="math display">\[\hat{\beta_{0}}=\sum_{i=1}^{n}\frac{y_{i}}{n}-ay_{i}\overline{x}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}(\frac{1}{n}-a\overline{x})y_{i}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\frac{1}{n}-\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)\overline{x}\right)y_{i}. \]</span>
Haciendo <span class="math inline">\(b=\frac{1}{n}-\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)\overline{x}\)</span> nada depende de <span class="math inline">\(y\)</span>, por lo que <span class="math inline">\(b\)</span> es constante, entonces la combinación lineal de <span class="math inline">\(y_{i}\)</span> para <span class="math inline">\(\hat{\beta_{0}}\)</span> es:</p>
<p><span class="math display">\[\therefore \hat{\beta_{0}}=\sum_{i=1}^{n}by_{i}.\]</span></p>
<p>“Regresando del paréntesis tenemos:”</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{1}}\right]=\mathbf{E}\left[\sum_{i=1}^{n}ay_{i}\right]\]</span>
<span class="math display">\[=\sum_{i=1}^{n}a\mathbf{E}[y_{i}].\]</span>
Tenemos que <span class="math inline">\(\mathbf{E}[y_{i}]=\beta_{0}+\beta_{1}x_{i}\)</span>, sustituyendo:</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{1}}\right]=\sum_{i=1}^{n}a(\beta_{0}+\beta_{1}x_{i})\]</span>
<span class="math display">\[=\sum_{i=1}^{n}a\beta_{0}+\sum_{i=1}^{n}a\beta_{1}x_{i}\]</span>
<span class="math display">\[=\beta_{0}\sum_{i=1}^{n}a+\beta_{1}\sum_{i=1}^{n}ax_{i}.\]</span>
Sustituyendo <span class="math inline">\(a\)</span> de la linealidad de <span class="math inline">\(\beta_{1}\)</span> se tiene:</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{1}}\right]=\beta_{0}\sum_{i=1}^{n}\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)+\beta_{1}\sum_{i=1}^{n}\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)x_{i}\]</span>
<span class="math display">\[=\frac{\beta_{0}}{S_{xx}}(n\overline{x}-\overline{x}n)+\frac{\beta_{1}}{S_{xx}}\sum_{i=1}^{n}(x_{i}-\overline{x})x_{i}.\]</span></p>
<p>Simplificando y recordando que <span class="math inline">\(\sum_{i=1}^{n}(x_{i}-\overline{x})x_{i}=S_{xx}\)</span></p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{1}}\right]=0+\frac{\beta_{1}}{S_{xx}}S_{xx}\]</span></p>
<p><span class="math display">\[\therefore \mathbf{E}\left[\hat{\beta_{1}}\right]=\beta_{1}\]</span></p>
<p>Por lo tanto el estimador <span class="math inline">\(\hat{\beta_{1}}\)</span> es insesgado. <span class="math inline">\(\blacksquare\)</span></p>
<p><strong>b)</strong> Ahora para demostrar el insesgamiento de <span class="math inline">\(\hat{\beta_{0}}\)</span>, se sustituye el estimador <span class="math inline">\(\hat{\beta_{0}}=\overline{y}-\hat{\beta_{1}}\overline{x}\)</span>, de esta forma tenemos:</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{0}}\right]=\mathbf{E}\left[\overline{y}-\hat{\beta_{1}}\overline{x}\right]\]</span>
<span class="math display">\[=\mathbf{E}\left[\overline{y}\right]-\mathbf{E}\left[\hat{\beta_{1}}\overline{x}\right]\]</span>
<span class="math display">\[=\mathbf{E}\left[\sum_{i=1}^{n}\frac{y_{i}}{n}\right]-\overline{x}\mathbf{E}\left[\hat{\beta_{1}}\right]\]</span>
Como el estimador de <span class="math inline">\(\beta_{1}\)</span> es insesgado:</p>
<p><span class="math display">\[=\sum_{i=1}^{n}\frac{1}{n}\mathbf{E}\left(y\right)-\overline{x}\beta_{1}.\]</span></p>
<p>y sabemos que <span class="math inline">\(\mathbf{E}(y)=\beta_{0}+\beta_{1}x,\)</span> sustituyendo tenemos:</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{\beta_{0}}\right]=\sum_{i=1}^{n}\frac{1}{n}(\beta_{0}+\beta_{1}x_{i})-\overline{x}\beta_{1}\]</span>
<span class="math display">\[=\beta_{0}+\beta_{1}\overline{x}-\overline{x}\beta_{1}\]</span>
<span class="math display">\[\therefore \mathbf{E}[\hat{\beta_{0}}]=\beta_{0}.\]</span>
Por lo tanto el estimador <span class="math inline">\(\hat{\beta_{0}}\)</span> es insesgado. <span class="math inline">\(\blacksquare\)</span></p>
<p>Ahora nos preguntaremos por la varianza de los estimadores, analizando qué tan distante está el estimador del parámetro buscado. Es decir, la varianza es el margen de error que obtiene en la estimación de los parámetros.</p>
<p><strong>Teorema 2.5</strong> Sea <span class="math inline">\(\hat{\beta_{0}}\)</span> <span class="math inline">\(\hat{\beta_{1}}\)</span> los estimadores puntuales de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> entonces la varianza de estimación</p>
<p><strong>a)</strong> <span class="math inline">\(Var\left(\hat{\beta_{0}}\right)=\left(\frac{1}{n}+\frac{\overline{x}^2}{S_{xx}}\right) \sigma^2.\)</span></p>
<p><strong>b)</strong> <span class="math inline">\(Var\left(\hat{\beta_{1}}\right)= \frac{1}{S_{xx}} \sigma^2.\)</span></p>
<p><strong>Demostración:</strong></p>
<p><strong>a)</strong></p>
<p><span class="math display">\[Var\left(\hat{\beta_{0}}\right)=Var\left(\overline{y}-\hat{\beta_{1}}\overline{x}\right)\]</span>
<span class="math display">\[=Var(\overline{y})+Var(\hat{\beta_{1}}\overline{x})-2Cov(\overline{y},\hat{\beta_{1}}\overline{x})\]</span>
<span class="math display">\[=Var(\overline{y})+Var(\hat{\beta_{1}}\overline{x})\]</span>
<span class="math display">\[=Var\left(\sum_{i=1}^{n}\frac{y_{i}}{n} \right)+\overline{x}^2Var(\hat{\beta_{1}})\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\frac{1}{n^2}Var(y_{i})+\overline{x}^2\frac{\sigma^2}{S_{xx}}\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\frac{1}{n^2}\sigma^2+\overline{x}^2\frac{\sigma^2}{S_{xx}}\]</span>
<span class="math display">\[\therefore Var\left(\hat{\beta_{0}}\right)=\left(\frac{1}{n}+\frac{\overline{x}^2}{S_{xx}}\right) \sigma^2. \blacksquare\]</span></p>
<p><strong>b)</strong></p>
<p><span class="math display">\[Var\left(\hat{\beta_{1}}\right)= Var\left( \frac{S_{xy}}{S_{xx}^2}\right)\]</span>
<span class="math display">\[= \frac{1}{S_{xx}}Var\left(S_{xy}\right)\]</span>
<span class="math display">\[=\frac{1}{S_{xx}^2}Var\left( \sum_{i=1}^{n}(x_{i}-\overline{x})y_{i}\right)\]</span>
<span class="math display">\[=\frac{1}{S_{xx}^2} \sum_{i=1}^{n}(x_{i}-\overline{x})^2Var(y_{i})\]</span>
<span class="math display">\[=\frac{1}{S_{xx}^2}\sum_{i=1}^{n}(x_{i}-\overline{x})^2Var(e_{i})\]</span></p>
<p><span class="math display">\[=\frac{1}{S_{xx}^2}S_{xx}\sigma^2\]</span></p>
<p><span class="math display">\[\therefore Var\left(\hat{\beta_{1}}\right)= \frac{1}{S_{xx}} \sigma^2. \blacksquare\]</span></p>
<p>Una característica importante de los estimadores obtenidos es que existe una covarianza conjunta entre <span class="math inline">\(\hat{\beta_{0}}\)</span> y <span class="math inline">\(\hat{\beta_{1}}\)</span>, que veremos a continuación:</p>
<p><strong>Teorema 2.6</strong> Sea <span class="math inline">\(\beta_{0}\)</span>,<span class="math inline">\(\beta_{1}\)</span> los estimadores puntuales de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> entonces la covarianza conjunta de los estimadores es:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sigma^2\left(-\frac{\overline{x}}{\sum_{i=1}^{n}(x_{i}-\overline{x})^2}\right)\]</span></p>
<p><strong>Demostración:</strong></p>
<p>Como mencionamos anteriormente, <span class="math inline">\(\hat{\beta_{0}},\hat{\beta_{1}}\)</span> pueden ser expresadas como combinaciones lineales de <span class="math inline">\(y\)</span> por lo que:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}} \right)= \mathbf{E}\left[ \left( \hat{\beta_{0}}-\mathbf{E}(\hat{\beta_{0}})\right)\left(\hat{\beta_{1}}-\mathbf{E}(\hat{\beta_{1})} \right) \right]\]</span>
<span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}} \right)= \mathbf{E}\left[\left(\sum_{i=1}^{n}a_{i}Y_{i}-\mathbf{E}(\sum_{i=1}^{n}a_{i}Y_{i}) \right)\left(\sum_{i=1}^{n}b_{i}Y_{i}-\mathbf{E}(\sum_{i=1}^{n}b_{i}Y_{i}) \right)\right].\]</span></p>
<p>Por linealidad de la esperanza:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sum_{i=1}^{n}a_{i}b_{i}\mathbf{E}[(Y_{i}-\mathbf{E}(Y_{i}))(Y_{i}-\mathbf{E}(Y_{i}))].\]</span>
Por propiedades de la esperanza:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sum_{i=1}^{n}a_{i}b_{i}Var[Y_{i}].\]</span>
Por el <strong>teorema 2.1</strong> se sabe que la varianza del modelo es:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sum_{i=1}^{n}a_{i}b_{i}\sigma^2\]</span>
Sustituyendo <span class="math inline">\(a=\frac{(x_{i}-\overline{x})}{S_{xx}}\)</span> y <span class="math inline">\(b=\frac{1}{n}-\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)\overline{x}\)</span> se tiene:</p>
<p><span class="math display">\[Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sum_{i=1}^{n}\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\left[\frac{1}{n}-\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)\overline{x}\right]\right)\sigma^2\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\frac{(x_{i}-\overline{x})}{nS_{xx}}-\left(\frac{(x_{i}-\overline{x})}{S_{xx}}\right)^2\overline{x}\right)\sigma^2\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\frac{(x_{i}-\overline{x})}{nS_{xx}}-\left(\frac{\overline{x}(x_{i}-\overline{x})}{S^2_{xx}}\right)^2\overline{x}\right)\sigma^2\]</span>
<span class="math display">\[=\sum_{i=1}^{n}\left(\frac{x_{i}-\overline{x}}{nS_{xx}}-\frac{\overline{x}(x_{i}-\overline{x})^2}{S^2_{xx}}\right)\sigma^2\]</span>
<span class="math display">\[=\left(\frac{\overline{x}n -n\overline{x}}{nS_{xx}}-\frac{\overline{x}S_{xx}}{S^2_{xx}}\right)\sigma^2\]</span>
<span class="math display">\[=\left(-\frac{\overline{x}}{S_{xx}}\right)\sigma^2\]</span></p>
<p><span class="math display">\[\therefore Cov\left(\hat{\beta_{0}},\hat{\beta_{1}}\right)=\sigma^2\left(-\frac{\overline{x}}{\sum_{i=1}^{n}(x_{i}-\overline{x})^2}\right).\blacksquare\]</span></p>
<p>Una consecuencia inmediata del <strong>teorema 2.3</strong> y <strong>teorema 2.4</strong>, es que si la suma de residuales es 0, implica que la esperanza del valor observado sea igual a la esperanza del valor estimado, es decir:</p>
<p><strong>Corolario 3</strong> Sea <span class="math inline">\(\hat{\beta_{0}},\hat{\beta_{1}}\)</span> los estimadores de mínimos cuadrados de <span class="math inline">\(\beta_{0}\)</span> y <span class="math inline">\(\beta_{1}\)</span> respectivamente, si se cumple el teorema 2.3, entonces la esperanza de los valores observados y la esperanza de los valores ajustados por la regresión son iguales, es decir:</p>
<p><span class="math display">\[\mathbf{E}\left[\hat{y_{i}}\right]=\mathbf{E}\left[ y_{i} \right]\]</span>
De esta manera lo que se debe demostrar es que se cumple la siguiente igualdad:</p>
<p><span class="math inline">\(\mathbf{Pd.} \ \ \mathbf{E}\left[ Y_{i}-\hat{y_{i}}\right]=0\)</span></p>
<p><strong>Demostración:</strong></p>
<p><span class="math inline">\(\mathbf{E}\left[ Y_{i}-\hat{y_{i}}\right]=\mathbf{E}\left[ Y_{i}\right]-\mathbf{E}\left[\hat{y_{i}}\right]\)</span></p>
<p><span class="math inline">\(=\beta_{0}+\beta_{1}x_{i}-\mathbf{E}\left[\hat{y_{i}}\right]\)</span>            Por el teorema 2.1</p>
<p><span class="math inline">\(=\beta_{0}+\beta_{1}x_{i}-\mathbf{E}\left[ \hat{\beta_{0}}+\hat{\beta_{1}}x_{i}\right]\)</span></p>
<p><span class="math inline">\(=\beta_{0}+\beta_{1}x_{i}-\mathbf{E}\left[ \hat{\beta_{0}}\right]-\mathbf{E}\left[\hat{\beta_{1}}x_{i}\right]\)</span></p>
<p><span class="math inline">\(=\beta_{0}+\beta_{1}x_{i}-\beta_{0}-\beta_{1}x_{i}\)</span>       Por el teorema 2.5 son insesgados</p>
<p><span class="math inline">\(\therefore \ \ \mathbf{E}\left[ Y_{i}-\hat{y_{i}}\right]=0.\  \blacksquare\)</span></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introducción-5.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelo-sin-intercepto.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "github", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
